{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShhreyashPandey/NLP/blob/main/NLP_Assign2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAyyS2_BMhbM"
      },
      "source": [
        "Shhreyash Pandey\n",
        "\n",
        "22070126105\n",
        "\n",
        "AIML-B2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83iehR2TMl5B"
      },
      "source": [
        "# AG News Classification Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgbsSAhTPspx"
      },
      "source": [
        "Preprocessing the dataset to get cleaned version of it and then saving it to reduce the computation load on every run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rZx9nFKMgmT",
        "outputId": "12c0e64d-334e-415e-c46d-eef3725f12ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (13 kB)\n",
            "Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "!pip install contractions\n",
        "import contractions\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Load SpaCy model for tokenization and lemmatization\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "arwwdKnAMx3I"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "p3EbZ2mBNaXD",
        "outputId": "0db4ea19-9258-40b4-ad0b-7bc774dba610"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Class Index                                              Title  \\\n",
              "0            3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
              "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
              "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
              "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
              "4            3  Oil prices soar to all-time record, posing new...   \n",
              "\n",
              "                                         Description  \n",
              "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
              "1  Reuters - Private investment firm Carlyle Grou...  \n",
              "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
              "3  Reuters - Authorities have halted oil export\\f...  \n",
              "4  AFP - Tearaway world oil prices, toppling reco...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4646ca92-733a-48ce-95ba-a08e03c9ef22\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4646ca92-733a-48ce-95ba-a08e03c9ef22')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4646ca92-733a-48ce-95ba-a08e03c9ef22 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4646ca92-733a-48ce-95ba-a08e03c9ef22');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-64073816-b402-4ae4-a75f-d7cc3c25a099\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64073816-b402-4ae4-a75f-d7cc3c25a099')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-64073816-b402-4ae4-a75f-d7cc3c25a099 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6ugI7XvNtrO",
        "outputId": "345f29ee-c267-42cf-8457-2014b6eb8c6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "DAbTS7tWNvJf",
        "outputId": "bc3e7224-58b1-42b1-c3b8-9ad99137317a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Class Index\n",
              "count  120000.000000\n",
              "mean        2.500000\n",
              "std         1.118039\n",
              "min         1.000000\n",
              "25%         1.750000\n",
              "50%         2.500000\n",
              "75%         3.250000\n",
              "max         4.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b406eb9-6fbe-4559-ba75-48d8e5616856\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>120000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.118039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b406eb9-6fbe-4559-ba75-48d8e5616856')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1b406eb9-6fbe-4559-ba75-48d8e5616856 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1b406eb9-6fbe-4559-ba75-48d8e5616856');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4df0cfb8-61b0-4bec-8a9b-87f04d3826ed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4df0cfb8-61b0-4bec-8a9b-87f04d3826ed')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4df0cfb8-61b0-4bec-8a9b-87f04d3826ed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Class Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 42425.59279953164,\n        \"min\": 1.0,\n        \"max\": 120000.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          120000.0,\n          2.5,\n          3.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "train.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "dU8-uZ8LNzYc",
        "outputId": "e0e564cc-522a-4318-a3f2-408b581205e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Class Index                                              Title  \\\n",
              "0            3                  Fears for T N pension after talks   \n",
              "1            4  The Race is On: Second Private Team Sets Launc...   \n",
              "2            4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
              "3            4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
              "4            4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
              "\n",
              "                                         Description  \n",
              "0  Unions representing workers at Turner   Newall...  \n",
              "1  SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
              "2  AP - A company founded by a chemistry research...  \n",
              "3  AP - It's barely dawn when Mike Fitzpatrick st...  \n",
              "4  AP - Southern California's smog-fighting agenc...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-40cb82e0-0b3f-46cc-b8d2-7fd9f8a22e82\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class Index</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Fears for T N pension after talks</td>\n",
              "      <td>Unions representing workers at Turner   Newall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
              "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
              "      <td>AP - A company founded by a chemistry research...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
              "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
              "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-40cb82e0-0b3f-46cc-b8d2-7fd9f8a22e82')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-40cb82e0-0b3f-46cc-b8d2-7fd9f8a22e82 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-40cb82e0-0b3f-46cc-b8d2-7fd9f8a22e82');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3ed49ca2-6ddd-432c-9ac6-ec1a49d448bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3ed49ca2-6ddd-432c-9ac6-ec1a49d448bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3ed49ca2-6ddd-432c-9ac6-ec1a49d448bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test",
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 7600,\n  \"fields\": [\n    {\n      \"column\": \"Class Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7568,\n        \"samples\": [\n          \"'Nano-needle' operates on cell\",\n          \"Russia Says Attack Was To Ignite Regional War\",\n          \"Olympics-Five sports on shortlist for possible Games inclusion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7594,\n        \"samples\": [\n          \"By Karen Pallarito, HealthDay Reporter    HealthDayNews -- Determined this cold season to nip your sneezing, runny nose and scratchy throat in the bud before those nasty respiratory symptoms sideline you?    There's a broad array of cold remedies you might want to try, ranging from over-the-counter preparations to basic ingredients tucked away in your kitchen pantry.    So what'll it be? A combination pain reliever and nasal decongestant? Vitamin C and echinacea? Tea with honey? A brimming bowl of chicken soup?     It turns out the best advice for dealing with the misery of a cold is the same principle mothers often apply when trying to coax their unruly toddlers to take a nap: Whatever works...\",\n          \"Hewlett-Packard Co. (HPQ.N: Quote, Profile, Research) and Intel Corp. (INTC.O: Quote, Profile, Research) on Wednesday ended their 10-year partnership to co-develop the Itanium chip \",\n          \"Japan #39;s baseball players averted a second strike this weekend after agreeing that a new team will be allowed to join Japanese professional baseball next season.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwnkzpn9N0oz",
        "outputId": "f76248b0-2e26-4147-f664-8555f80506e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7600, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hD5VnH92OZuY"
      },
      "outputs": [],
      "source": [
        "# Remove empty rows and duplicates from both train and test set\n",
        "train.dropna(inplace=True)\n",
        "train.drop_duplicates(inplace=True)\n",
        "\n",
        "test.dropna(inplace=True)\n",
        "test.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK9rSw-3ksaR",
        "outputId": "92c1b9a5-0a42-40fb-e7c2-ed19b1cce532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(120000, 3)\n",
            "(7600, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing"
      ],
      "metadata": {
        "id": "HPYo1SwJkxyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Regular Expression\n",
        "regexp = RegexpTokenizer(\"[\\w']+\")"
      ],
      "metadata": {
        "id": "f3LQWwgak0rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lowercase\n",
        "def text_lower(text):\n",
        "  text = text.lower()\n",
        "  return text"
      ],
      "metadata": {
        "id": "Rdg0Xrk7k3-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Whitespace\n",
        "def remove_whitespace(text):\n",
        "  text = re.sub(r'\\s+', ' ', text).strip()\n",
        "  return text"
      ],
      "metadata": {
        "id": "_Js000jAk50r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Punctuation\n",
        "def remove_punctuation(text):\n",
        "  punct = string.punctuation\n",
        "  punct = punct.replace(\"'\",\"\")\n",
        "  text = text.translate(str.maketrans(\"\", \"\",punct))\n",
        "  return text"
      ],
      "metadata": {
        "id": "loakgdMtlVvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove HTML\n",
        "def remove_html(text):\n",
        "  html = re.compile(r'<.*?>')\n",
        "  text = html.sub(r'',text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "QNyRtnkKlma8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing emojis\n",
        "def remove_emoji(text):\n",
        "  emoji_pattern = re.compile(\"[\"\n",
        "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags\n",
        "    u\"\\U00002702-\\U000027B0\"\n",
        "    u\"\\U000024C2-\\U0001F251\"\n",
        "    \"]+\",flags=re.UNICODE\n",
        "  )\n",
        "  text = emoji_pattern.sub(r'',text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "ohse9eg_lo5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove URLS\n",
        "def remove_http_links(text):\n",
        "  text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "  return text"
      ],
      "metadata": {
        "id": "06a672fDlyS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Contractions\n",
        "def convert_contractions(text):\n",
        "  text = contractions.fix(text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "aNGEoVz1mBWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Stopwords\n",
        "def remove_stopwords(text):\n",
        "  text = \" \".join([word for word in nltk.tokenize.word_tokenize(text) if word not in stopwords.words('english')])\n",
        "  return text"
      ],
      "metadata": {
        "id": "WTaZe1ZomEOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization\n",
        "def lemmatize(text):\n",
        "  text = \" \".join([token.lemma_ for token in nlp(text)])\n",
        "  return text"
      ],
      "metadata": {
        "id": "-AHMX-jmmQth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove Non-Alphabetic Characters\n",
        "def discard_non_alpha(text):\n",
        "  word_list_non_alpha = [word for word in regexp.tokenize(text) if word.isalpha()]\n",
        "  text = \" \".join(word_list_non_alpha)\n",
        "  return text"
      ],
      "metadata": {
        "id": "CmwTg4nGmXor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjABnWu3PeoD"
      },
      "outputs": [],
      "source": [
        "#Aggregating All definitions\n",
        "def preprocess_text(text):\n",
        "  text = text_lower(text)\n",
        "  text = remove_whitespace(text)\n",
        "  text = re.sub('\\n' , '', text)\n",
        "  text = re.sub('\\[.*?\\]', '', text)\n",
        "  text = remove_http_links(text)\n",
        "  text = remove_punctuation(text)\n",
        "  text = remove_html(text)\n",
        "  text = remove_emoji(text)\n",
        "  #text = convert_abbrev(text)\n",
        "  text = convert_contractions(text)\n",
        "  text = remove_stopwords(text)\n",
        "  text = discard_non_alpha(text)\n",
        "  text = lemmatize(text)\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w4GA2nLOb8w"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to the dataset\n",
        "train['cleaned_description'] = train['Description'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTpd9GD0OFsE"
      },
      "outputs": [],
      "source": [
        "# Applying on testing set\n",
        "test['cleaned_description'] = test['Description'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iK5jFuhNP0kW",
        "outputId": "58b69c34-6c92-414b-cd32-5240dfd17833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed data saved successfully!\n"
          ]
        }
      ],
      "source": [
        "# Save the processed data to CSV files\n",
        "train.to_csv('processed_train.csv', index=False)\n",
        "test.to_csv('processed_test.csv', index=False)\n",
        "\n",
        "print(\"Processed data saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, applying LSTM Model on preprocessed dataset"
      ],
      "metadata": {
        "id": "SID7ALGnYU8Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsJ2T-_hP16X"
      },
      "outputs": [],
      "source": [
        "# Load the preprocessed datasets\n",
        "train = pd.read_csv('/content/processed_train.csv')\n",
        "test = pd.read_csv('/content/processed_test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlAK7e7ZIbuU"
      },
      "source": [
        "The Tokenizer assigns an index to each word in the dataset. If the max_words parameter is set to 10,000, the indices for words should range between 0 and 9,999."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHegiDJ4P5S2",
        "outputId": "12a6a7ed-66a7-463b-bffc-fd14c6552b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum sentence length: 95\n"
          ]
        }
      ],
      "source": [
        "# Finding max length of sentence in the dataset\n",
        "max_sequence_length = train['cleaned_description'].apply(lambda x: len(x.split())).max()\n",
        "print(\"Maximum sentence length:\", max_sequence_length)\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train['cleaned_description'])\n",
        "\n",
        "# Convert text to sequences\n",
        "sequences = tokenizer.texts_to_sequences(train['cleaned_description'])\n",
        "\n",
        "# Pad sequences\n",
        "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Split data into train and test sets\n",
        "y = train['Class Index']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting parameters and training LSTM Models\n",
        "1. Single Layer LSTM\n",
        "2. Two Layer LSTM\n",
        "\n",
        "Printing their classification report and confusion matrix."
      ],
      "metadata": {
        "id": "cA7kQZJ7ZNS-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgcJ2HYIbjJc"
      },
      "outputs": [],
      "source": [
        "# Parameters for Set 1\n",
        "batch_size_1 = 4\n",
        "max_sequence_length_1=max_sequence_length\n",
        "embedding_dim_1 = 10\n",
        "lstm_units_1 = 8\n",
        "max_words_1 = 10000\n",
        "\n",
        "# Parameters for Set 2\n",
        "batch_size_2 = 8\n",
        "max_sequence_length_2= max_sequence_length\n",
        "embedding_dim_2 = 30\n",
        "lstm_units_2 = 16\n",
        "max_words_2 = 25000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiqqP_xqS7WV",
        "outputId": "2886466c-74de-4352-e9d2-7f97b8c15369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m19200/19200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 32ms/step - accuracy: 0.2490 - loss: -67.4049 - val_accuracy: 0.2514 - val_loss: -249.8148\n",
            "Epoch 2/5\n",
            "\u001b[1m19200/19200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m607s\u001b[0m 31ms/step - accuracy: 0.2524 - loss: -310.3482 - val_accuracy: 0.2514 - val_loss: -492.5465\n",
            "Epoch 3/5\n",
            "\u001b[1m19200/19200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 30ms/step - accuracy: 0.2514 - loss: -552.0841 - val_accuracy: 0.2514 - val_loss: -735.5290\n",
            "Epoch 4/5\n",
            "\u001b[1m19200/19200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m580s\u001b[0m 30ms/step - accuracy: 0.2506 - loss: -798.0848 - val_accuracy: 0.2514 - val_loss: -978.2407\n",
            "Epoch 5/5\n",
            "\u001b[1m19200/19200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m620s\u001b[0m 30ms/step - accuracy: 0.2502 - loss: -1038.1273 - val_accuracy: 0.2514 - val_loss: -1221.2896\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78f91a014700>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# Model 1: Single-layer LSTM\n",
        "model1 = Sequential()\n",
        "model1.add(Embedding(input_dim=max_words_1, output_dim=embedding_dim_1, input_length=max_sequence_length_1))\n",
        "model1.add(LSTM(units=lstm_units_1))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model1.fit(X_train, y_train, epochs=5, batch_size=batch_size_1, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7SnbiBwS842",
        "outputId": "05c7ad1c-f68c-42db-ee45-0911b3251d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m657s\u001b[0m 68ms/step - accuracy: 0.2518 - loss: -66.2587 - val_accuracy: 0.2514 - val_loss: -244.5592\n",
            "Epoch 2/5\n",
            "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m685s\u001b[0m 68ms/step - accuracy: 0.2492 - loss: -304.3578 - val_accuracy: 0.2514 - val_loss: -480.9278\n",
            "Epoch 3/5\n",
            "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 69ms/step - accuracy: 0.2484 - loss: -540.1713 - val_accuracy: 0.2514 - val_loss: -717.3910\n",
            "Epoch 4/5\n",
            "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m678s\u001b[0m 68ms/step - accuracy: 0.2520 - loss: -776.4479 - val_accuracy: 0.2514 - val_loss: -954.0824\n",
            "Epoch 5/5\n",
            "\u001b[1m9600/9600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 68ms/step - accuracy: 0.2509 - loss: -1011.8498 - val_accuracy: 0.2514 - val_loss: -1190.7961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78f910ae0550>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Model 2: Two-layer LSTM\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(input_dim=max_words_2, output_dim=embedding_dim_2, input_length=max_sequence_length_2))\n",
        "model2.add(LSTM(units=lstm_units_2, return_sequences=True))\n",
        "model2.add(LSTM(units=lstm_units_2))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model2.fit(X_train, y_train, epochs=5, batch_size=batch_size_2, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0P_a59AHsWs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "outputId": "8ac88ee1-adbb-454e-b2c4-a48c50fea5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step\n",
            "Set 1 Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.25      1.00      0.40      5956\n",
            "           2       0.00      0.00      0.00      6058\n",
            "           3       0.00      0.00      0.00      5911\n",
            "           4       0.00      0.00      0.00      6075\n",
            "\n",
            "    accuracy                           0.25     24000\n",
            "   macro avg       0.06      0.25      0.10     24000\n",
            "weighted avg       0.06      0.25      0.10     24000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Convert predictions to binary\n",
        "preds1 = model1.predict(X_test)\n",
        "preds1 = (preds1 > 0.5).astype(int)\n",
        "\n",
        "# Classification Report\n",
        "print(\"Set 1 Classification Report\")\n",
        "print(classification_report(y_test, preds1))\n",
        "\n",
        "# Confusion Matrix with Heatmap for Set 1\n",
        "cm1 = confusion_matrix(y_test, preds1)\n",
        "sns.heatmap(cm1, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix for Set 1\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "1cbekqfcTDiw",
        "outputId": "954d8ebd-bcfe-4fb7-958d-90cea7f983ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step\n",
            "Set 2 Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.25      1.00      0.40      5956\n",
            "           2       0.00      0.00      0.00      6058\n",
            "           3       0.00      0.00      0.00      5911\n",
            "           4       0.00      0.00      0.00      6075\n",
            "\n",
            "    accuracy                           0.25     24000\n",
            "   macro avg       0.06      0.25      0.10     24000\n",
            "weighted avg       0.06      0.25      0.10     24000\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Convert predictions to binary\n",
        "preds2 = model2.predict(X_test)\n",
        "preds2 = (preds2 > 0.5).astype(int)\n",
        "\n",
        "# Classification Report\n",
        "print(\"Set 2 Classification Report\")\n",
        "print(classification_report(y_test, preds2))\n",
        "\n",
        "# Confusion Matrix with Heatmap for Set 2\n",
        "cm2 = confusion_matrix(y_test, preds2)\n",
        "sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix for Set 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training few more models with different number of layers and different parameters set to increase the accuracy of the trained model."
      ],
      "metadata": {
        "id": "Qohv6NGnZwK1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4_H1TS5HgyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60487478-00d0-41ed-cbb2-53873148b6e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m518s\u001b[0m 105ms/step - accuracy: 0.2516 - loss: -70.1360 - val_accuracy: 0.2514 - val_loss: -246.6379\n",
            "Epoch 2/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m555s\u001b[0m 104ms/step - accuracy: 0.2499 - loss: -304.6071 - val_accuracy: 0.2514 - val_loss: -480.1788\n",
            "Epoch 3/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 105ms/step - accuracy: 0.2512 - loss: -538.2863 - val_accuracy: 0.2514 - val_loss: -713.6916\n",
            "Epoch 4/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 103ms/step - accuracy: 0.2498 - loss: -771.2616 - val_accuracy: 0.2514 - val_loss: -947.2249\n",
            "Epoch 5/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 103ms/step - accuracy: 0.2505 - loss: -1004.6306 - val_accuracy: 0.2514 - val_loss: -1180.5095\n",
            "Epoch 6/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 103ms/step - accuracy: 0.2502 - loss: -1238.8169 - val_accuracy: 0.2514 - val_loss: -1414.2094\n",
            "Epoch 7/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 102ms/step - accuracy: 0.2511 - loss: -1469.5076 - val_accuracy: 0.2514 - val_loss: -1647.7360\n",
            "Epoch 8/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 102ms/step - accuracy: 0.2511 - loss: -1698.4227 - val_accuracy: 0.2514 - val_loss: -1881.3113\n",
            "Epoch 9/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 102ms/step - accuracy: 0.2491 - loss: -1945.7000 - val_accuracy: 0.2514 - val_loss: -2114.2737\n",
            "Epoch 10/10\n",
            "\u001b[1m4800/4800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 103ms/step - accuracy: 0.2511 - loss: -2169.1863 - val_accuracy: 0.2514 - val_loss: -2347.8162\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x78f911272590>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# Parameters for Set 3\n",
        "batch_size_3 = 16\n",
        "max_sequence_length_3 = 10000\n",
        "embedding_dim_3 = 10\n",
        "lstm_units_3 = 32\n",
        "max_words_3 = 30000\n",
        "\n",
        "# Model 3: Three-layer LSTM with better accuracy\n",
        "model3 = Sequential()\n",
        "model3.add(Embedding(input_dim=max_words_3, output_dim=embedding_dim_3, input_length=max_sequence_length_3))\n",
        "model3.add(LSTM(units=lstm_units_3, return_sequences=True))\n",
        "model3.add(LSTM(units=lstm_units_3, return_sequences=True))\n",
        "model3.add(LSTM(units=lstm_units_3))\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model3.fit(X_train, y_train, epochs=10, batch_size=batch_size_3, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for Set 4\n",
        "batch_size_4 = 32\n",
        "max_sequence_length_4 = 10000\n",
        "embedding_dim_4 = 20\n",
        "lstm_units_4 = 40\n",
        "max_words_4 = 40000\n",
        "\n",
        "# Model 4: Four-layer LSTM with better accuracy\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(input_dim=max_words_4, output_dim=embedding_dim_4, input_length=max_sequence_length_4))\n",
        "model4.add(LSTM(units=lstm_units_4, return_sequences=True))\n",
        "model4.add(LSTM(units=lstm_units_4, return_sequences=True))\n",
        "model4.add(LSTM(units=lstm_units_4, return_sequences=True))\n",
        "model4.add(LSTM(units=lstm_units_4))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model4.fit(X_train, y_train, epochs=10, batch_size=batch_size_4, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV4EW6iwRC9Y",
        "outputId": "00accf54-8a83-4256-bcce-fe4746c96bfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 167ms/step - accuracy: 0.2500 - loss: -50.4228 - val_accuracy: 0.2514 - val_loss: -162.3777\n",
            "Epoch 2/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 162ms/step - accuracy: 0.2534 - loss: -198.4246 - val_accuracy: 0.2514 - val_loss: -308.8767\n",
            "Epoch 3/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 170ms/step - accuracy: 0.2497 - loss: -345.2394 - val_accuracy: 0.2514 - val_loss: -455.0283\n",
            "Epoch 4/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 161ms/step - accuracy: 0.2501 - loss: -490.8523 - val_accuracy: 0.2514 - val_loss: -601.3679\n",
            "Epoch 5/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 163ms/step - accuracy: 0.2482 - loss: -638.8656 - val_accuracy: 0.2514 - val_loss: -747.2888\n",
            "Epoch 6/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 164ms/step - accuracy: 0.2498 - loss: -782.7460 - val_accuracy: 0.2514 - val_loss: -893.7407\n",
            "Epoch 7/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 164ms/step - accuracy: 0.2527 - loss: -928.7026 - val_accuracy: 0.2514 - val_loss: -1039.9996\n",
            "Epoch 8/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 166ms/step - accuracy: 0.2493 - loss: -1077.0847 - val_accuracy: 0.2514 - val_loss: -1186.1113\n",
            "Epoch 9/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m437s\u001b[0m 164ms/step - accuracy: 0.2502 - loss: -1222.4938 - val_accuracy: 0.2514 - val_loss: -1332.4080\n",
            "Epoch 10/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 164ms/step - accuracy: 0.2501 - loss: -1365.9663 - val_accuracy: 0.2514 - val_loss: -1478.7142\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x796098af0cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for Set 5\n",
        "batch_size_5 = 32\n",
        "max_sequence_length_5 = 10000\n",
        "embedding_dim_5 = 20\n",
        "lstm_units_5 = 40\n",
        "max_words_5 = 40000\n",
        "\n",
        "# Model 4: Four-layer LSTM with better accuracy\n",
        "model4 = Sequential()\n",
        "model4.add(Embedding(input_dim=max_words_5, output_dim=embedding_dim_5, input_length=max_sequence_length_5))\n",
        "model4.add(LSTM(units=lstm_units_5, return_sequences=True))\n",
        "model4.add(LSTM(units=lstm_units_5, return_sequences=True))\n",
        "model4.add(LSTM(units=lstm_units_5, return_sequences=True))\n",
        "model4.add(LSTM(units=lstm_units_5))\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model4.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model4.fit(X_train, y_train, epochs=10, batch_size=batch_size_5, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivW0BmkO3Y2G",
        "outputId": "63cfbb82-ad85-4f57-8212-c3fa869463da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 172ms/step - accuracy: 0.2510 - loss: -49.9303 - val_accuracy: 0.2514 - val_loss: -161.9198\n",
            "Epoch 2/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 172ms/step - accuracy: 0.2507 - loss: -198.1964 - val_accuracy: 0.2514 - val_loss: -308.2999\n",
            "Epoch 3/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 164ms/step - accuracy: 0.2513 - loss: -342.7008 - val_accuracy: 0.2514 - val_loss: -454.7644\n",
            "Epoch 4/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m457s\u001b[0m 171ms/step - accuracy: 0.2501 - loss: -492.0368 - val_accuracy: 0.2514 - val_loss: -600.6752\n",
            "Epoch 5/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 173ms/step - accuracy: 0.2497 - loss: -636.9741 - val_accuracy: 0.2514 - val_loss: -747.0337\n",
            "Epoch 6/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 165ms/step - accuracy: 0.2513 - loss: -783.4189 - val_accuracy: 0.2514 - val_loss: -893.2437\n",
            "Epoch 7/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 166ms/step - accuracy: 0.2499 - loss: -932.4196 - val_accuracy: 0.2514 - val_loss: -1039.4160\n",
            "Epoch 8/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 167ms/step - accuracy: 0.2459 - loss: -1081.3286 - val_accuracy: 0.2514 - val_loss: -1185.7434\n",
            "Epoch 9/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 174ms/step - accuracy: 0.2508 - loss: -1220.3989 - val_accuracy: 0.2514 - val_loss: -1332.0515\n",
            "Epoch 10/10\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 167ms/step - accuracy: 0.2478 - loss: -1373.0715 - val_accuracy: 0.2514 - val_loss: -1478.2227\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x796088d43c10>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy of LSTM Model is around 25% only, even with varibale set of parameters. For this dataset, we can say that Machine Learning Models performed better than LSTM(on comparing the Assignment 1 and 2)"
      ],
      "metadata": {
        "id": "judSC7kVx7Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividing Data into Chunks and then train the model sequentially."
      ],
      "metadata": {
        "id": "Tn9ltqEDGRR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "batch_size = 4\n",
        "max_words = 10000\n",
        "embedding_dim = 10\n",
        "lstm_units = 8\n",
        "epochs = 5\n",
        "\n",
        "# Function to split data into chunks\n",
        "def chunk_data(X, y, chunk_size):\n",
        "    num_chunks = len(X) // chunk_size + int(len(X) % chunk_size != 0)\n",
        "    X_chunks = np.array_split(X, num_chunks)\n",
        "    y_chunks = np.array_split(y, num_chunks)\n",
        "    return X_chunks, y_chunks\n",
        "\n",
        "# Initialize the model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "    model.add(LSTM(units=lstm_units, return_sequences=True))\n",
        "    model.add(LSTM(units=lstm_units))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize the model for the first chunk\n",
        "model = create_model()\n",
        "\n",
        "# Split the data into chunks\n",
        "chunk_size = 1000  # Define the size of each chunk\n",
        "X_chunks, y_chunks = chunk_data(X_train, y_train, chunk_size)\n",
        "\n",
        "# Iterative training process\n",
        "for i, (X_chunk, y_chunk) in enumerate(zip(X_chunks, y_chunks)):\n",
        "    print(f\"Training on chunk {i+1}/{len(X_chunks)}\")\n",
        "\n",
        "    # Fit the model on the current chunk\n",
        "    model.fit(X_chunk, y_chunk, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "    # Optionally save the model weights after each chunk\n",
        "    model.save_weights(f\"model_weights_chunk_{i+1}.weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAukRAm0GQJd",
        "outputId": "2204f915-a691-495c-9762-0a2870429a45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on chunk 1/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 118ms/step - accuracy: 0.2746 - loss: -1.2264 - val_accuracy: 0.2350 - val_loss: -5.9944\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.2574 - loss: -7.0693 - val_accuracy: 0.2350 - val_loss: -9.2613\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.2619 - loss: -9.8623 - val_accuracy: 0.2350 - val_loss: -12.0658\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.2759 - loss: -12.2250 - val_accuracy: 0.2350 - val_loss: -14.7835\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.2607 - loss: -15.3367 - val_accuracy: 0.2350 - val_loss: -17.4161\n",
            "Training on chunk 2/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2556 - loss: -18.4379 - val_accuracy: 0.2450 - val_loss: -20.1503\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2603 - loss: -21.0311 - val_accuracy: 0.2450 - val_loss: -22.8121\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.2649 - loss: -22.8390 - val_accuracy: 0.2450 - val_loss: -25.4357\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2375 - loss: -26.6287 - val_accuracy: 0.2450 - val_loss: -28.0448\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2434 - loss: -29.3670 - val_accuracy: 0.2450 - val_loss: -30.6474\n",
            "Training on chunk 3/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2281 - loss: -32.1653 - val_accuracy: 0.2300 - val_loss: -32.8569\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.2531 - loss: -33.4030 - val_accuracy: 0.2300 - val_loss: -35.3444\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2511 - loss: -35.4480 - val_accuracy: 0.2300 - val_loss: -37.8755\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.2620 - loss: -38.0434 - val_accuracy: 0.2300 - val_loss: -40.3734\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.2571 - loss: -40.9024 - val_accuracy: 0.2300 - val_loss: -42.8888\n",
            "Training on chunk 4/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.2748 - loss: -42.3318 - val_accuracy: 0.2450 - val_loss: -46.6233\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.2459 - loss: -45.8647 - val_accuracy: 0.2450 - val_loss: -49.2125\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2208 - loss: -51.4859 - val_accuracy: 0.2450 - val_loss: -51.7897\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2660 - loss: -50.9773 - val_accuracy: 0.2450 - val_loss: -54.3596\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.2596 - loss: -50.9979 - val_accuracy: 0.2450 - val_loss: -56.9315\n",
            "Training on chunk 5/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2829 - loss: -51.9629 - val_accuracy: 0.2450 - val_loss: -60.0379\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.2583 - loss: -56.1733 - val_accuracy: 0.2450 - val_loss: -62.5656\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.2736 - loss: -57.6264 - val_accuracy: 0.2450 - val_loss: -65.1328\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2737 - loss: -61.4959 - val_accuracy: 0.2450 - val_loss: -67.7029\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.2694 - loss: -62.8370 - val_accuracy: 0.2450 - val_loss: -70.2453\n",
            "Training on chunk 6/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2532 - loss: -66.3197 - val_accuracy: 0.2250 - val_loss: -74.0149\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2558 - loss: -69.1880 - val_accuracy: 0.2250 - val_loss: -76.6143\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.2330 - loss: -73.1835 - val_accuracy: 0.2250 - val_loss: -79.2569\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.2584 - loss: -72.3030 - val_accuracy: 0.2250 - val_loss: -81.8727\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2541 - loss: -74.5572 - val_accuracy: 0.2250 - val_loss: -84.5117\n",
            "Training on chunk 7/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 42ms/step - accuracy: 0.2484 - loss: -83.0425 - val_accuracy: 0.2350 - val_loss: -84.9813\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2665 - loss: -83.0785 - val_accuracy: 0.2350 - val_loss: -87.6116\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.2637 - loss: -85.5560 - val_accuracy: 0.2350 - val_loss: -90.2241\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2730 - loss: -85.3776 - val_accuracy: 0.2350 - val_loss: -92.8113\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.2576 - loss: -92.0717 - val_accuracy: 0.2350 - val_loss: -95.4164\n",
            "Training on chunk 8/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2403 - loss: -95.6475 - val_accuracy: 0.2150 - val_loss: -102.8377\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.2511 - loss: -98.2425 - val_accuracy: 0.2150 - val_loss: -105.5836\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.2563 - loss: -98.3556 - val_accuracy: 0.2150 - val_loss: -108.2986\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.2537 - loss: -103.9936 - val_accuracy: 0.2150 - val_loss: -111.0457\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.2643 - loss: -103.4428 - val_accuracy: 0.2150 - val_loss: -113.7605\n",
            "Training on chunk 9/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2267 - loss: -110.7007 - val_accuracy: 0.2900 - val_loss: -104.5964\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2401 - loss: -109.1528 - val_accuracy: 0.2900 - val_loss: -107.0857\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.2207 - loss: -115.9197 - val_accuracy: 0.2900 - val_loss: -109.5483\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.2792 - loss: -111.4213 - val_accuracy: 0.2900 - val_loss: -112.0221\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.2452 - loss: -117.3163 - val_accuracy: 0.2900 - val_loss: -114.4995\n",
            "Training on chunk 10/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2434 - loss: -119.0049 - val_accuracy: 0.2450 - val_loss: -118.6126\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 43ms/step - accuracy: 0.2180 - loss: -128.6286 - val_accuracy: 0.2450 - val_loss: -121.1358\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2241 - loss: -127.2285 - val_accuracy: 0.2450 - val_loss: -123.6614\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2256 - loss: -129.7844 - val_accuracy: 0.2450 - val_loss: -126.1745\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.2243 - loss: -134.3798 - val_accuracy: 0.2450 - val_loss: -128.6844\n",
            "Training on chunk 11/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2231 - loss: -133.9609 - val_accuracy: 0.2450 - val_loss: -130.2619\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.2031 - loss: -139.6726 - val_accuracy: 0.2450 - val_loss: -132.7159\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2296 - loss: -134.8565 - val_accuracy: 0.2450 - val_loss: -135.1814\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2181 - loss: -144.9856 - val_accuracy: 0.2450 - val_loss: -137.6250\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 44ms/step - accuracy: 0.2550 - loss: -138.4476 - val_accuracy: 0.2450 - val_loss: -140.0926\n",
            "Training on chunk 12/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2440 - loss: -143.4315 - val_accuracy: 0.2550 - val_loss: -147.8477\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.2339 - loss: -149.4867 - val_accuracy: 0.2550 - val_loss: -150.3345\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.2665 - loss: -144.6137 - val_accuracy: 0.2550 - val_loss: -152.8194\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.2710 - loss: -146.3231 - val_accuracy: 0.2550 - val_loss: -155.3284\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.2751 - loss: -144.9878 - val_accuracy: 0.2550 - val_loss: -157.8144\n",
            "Training on chunk 13/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.2636 - loss: -153.6031 - val_accuracy: 0.2650 - val_loss: -155.0291\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.2398 - loss: -158.7759 - val_accuracy: 0.2650 - val_loss: -157.4903\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.2510 - loss: -155.7231 - val_accuracy: 0.2650 - val_loss: -159.9111\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2415 - loss: -166.1152 - val_accuracy: 0.2650 - val_loss: -162.3828\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.2610 - loss: -165.1902 - val_accuracy: 0.2650 - val_loss: -164.8278\n",
            "Training on chunk 14/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.2630 - loss: -169.3467 - val_accuracy: 0.2400 - val_loss: -174.7768\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.2627 - loss: -170.3271 - val_accuracy: 0.2400 - val_loss: -177.3786\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.2558 - loss: -181.6273 - val_accuracy: 0.2400 - val_loss: -179.9600\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.2619 - loss: -179.6640 - val_accuracy: 0.2400 - val_loss: -182.5489\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 43ms/step - accuracy: 0.2707 - loss: -176.8081 - val_accuracy: 0.2400 - val_loss: -185.1368\n",
            "Training on chunk 15/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2202 - loss: -191.5441 - val_accuracy: 0.2400 - val_loss: -185.9631\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2294 - loss: -193.4273 - val_accuracy: 0.2400 - val_loss: -188.5764\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 44ms/step - accuracy: 0.2060 - loss: -211.9111 - val_accuracy: 0.2400 - val_loss: -191.1864\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2246 - loss: -196.8620 - val_accuracy: 0.2400 - val_loss: -193.7975\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2157 - loss: -203.3083 - val_accuracy: 0.2400 - val_loss: -196.3849\n",
            "Training on chunk 16/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2431 - loss: -200.0786 - val_accuracy: 0.2250 - val_loss: -214.0806\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2642 - loss: -197.2698 - val_accuracy: 0.2250 - val_loss: -216.8133\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2516 - loss: -196.1638 - val_accuracy: 0.2250 - val_loss: -219.5305\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 45ms/step - accuracy: 0.2400 - loss: -201.0124 - val_accuracy: 0.2250 - val_loss: -222.2915\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.2388 - loss: -210.5435 - val_accuracy: 0.2250 - val_loss: -225.0352\n",
            "Training on chunk 17/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2327 - loss: -217.2888 - val_accuracy: 0.2100 - val_loss: -227.1076\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.2373 - loss: -223.6302 - val_accuracy: 0.2100 - val_loss: -229.8692\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2251 - loss: -227.7290 - val_accuracy: 0.2100 - val_loss: -232.6366\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2342 - loss: -220.5588 - val_accuracy: 0.2100 - val_loss: -235.3682\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 43ms/step - accuracy: 0.2309 - loss: -227.6493 - val_accuracy: 0.2100 - val_loss: -238.1543\n",
            "Training on chunk 18/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2313 - loss: -231.4145 - val_accuracy: 0.2600 - val_loss: -209.6434\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.2379 - loss: -234.0911 - val_accuracy: 0.2600 - val_loss: -212.0186\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.2149 - loss: -238.4827 - val_accuracy: 0.2600 - val_loss: -214.4026\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.2450 - loss: -227.0383 - val_accuracy: 0.2600 - val_loss: -216.7722\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.2260 - loss: -235.3875 - val_accuracy: 0.2600 - val_loss: -219.1618\n",
            "Training on chunk 19/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.2210 - loss: -234.4057 - val_accuracy: 0.2850 - val_loss: -223.8827\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.2370 - loss: -241.4802 - val_accuracy: 0.2850 - val_loss: -226.2861\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.2246 - loss: -250.2084 - val_accuracy: 0.2850 - val_loss: -228.6671\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.2340 - loss: -238.4852 - val_accuracy: 0.2850 - val_loss: -231.0741\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2299 - loss: -242.4794 - val_accuracy: 0.2850 - val_loss: -233.4880\n",
            "Training on chunk 20/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2067 - loss: -264.0336 - val_accuracy: 0.2450 - val_loss: -252.6148\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.2210 - loss: -269.4208 - val_accuracy: 0.2450 - val_loss: -255.2974\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.2186 - loss: -273.4978 - val_accuracy: 0.2450 - val_loss: -257.9734\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 54ms/step - accuracy: 0.2252 - loss: -272.8068 - val_accuracy: 0.2450 - val_loss: -260.6506\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.2128 - loss: -283.4077 - val_accuracy: 0.2450 - val_loss: -263.2888\n",
            "Training on chunk 21/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.2497 - loss: -259.1768 - val_accuracy: 0.2450 - val_loss: -267.5533\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2388 - loss: -271.0839 - val_accuracy: 0.2450 - val_loss: -270.0990\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.2466 - loss: -265.6860 - val_accuracy: 0.2450 - val_loss: -272.6433\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.2254 - loss: -279.9564 - val_accuracy: 0.2450 - val_loss: -275.2168\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.2240 - loss: -286.4029 - val_accuracy: 0.2450 - val_loss: -277.7773\n",
            "Training on chunk 22/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2388 - loss: -272.0156 - val_accuracy: 0.2100 - val_loss: -295.8874\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.2503 - loss: -274.8182 - val_accuracy: 0.2100 - val_loss: -298.6094\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2328 - loss: -285.1608 - val_accuracy: 0.2100 - val_loss: -301.3284\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2339 - loss: -287.4052 - val_accuracy: 0.2100 - val_loss: -304.0706\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.2547 - loss: -279.3559 - val_accuracy: 0.2100 - val_loss: -306.7993\n",
            "Training on chunk 23/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2929 - loss: -265.1086 - val_accuracy: 0.2350 - val_loss: -290.3023\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.2904 - loss: -266.0047 - val_accuracy: 0.2350 - val_loss: -292.7484\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 49ms/step - accuracy: 0.2943 - loss: -275.2910 - val_accuracy: 0.2350 - val_loss: -295.2157\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.2741 - loss: -283.1637 - val_accuracy: 0.2350 - val_loss: -297.6849\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.2479 - loss: -290.3884 - val_accuracy: 0.2350 - val_loss: -300.1725\n",
            "Training on chunk 24/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2155 - loss: -307.1156 - val_accuracy: 0.1850 - val_loss: -337.7338\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.2005 - loss: -318.7472 - val_accuracy: 0.1850 - val_loss: -340.7026\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.2119 - loss: -324.8403 - val_accuracy: 0.1850 - val_loss: -343.6603\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.2501 - loss: -301.6895 - val_accuracy: 0.1850 - val_loss: -346.6328\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2260 - loss: -323.0719 - val_accuracy: 0.1850 - val_loss: -349.5635\n",
            "Training on chunk 25/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 44ms/step - accuracy: 0.2266 - loss: -304.1001 - val_accuracy: 0.2300 - val_loss: -333.5911\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2576 - loss: -291.5479 - val_accuracy: 0.2300 - val_loss: -336.1846\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.2333 - loss: -309.5802 - val_accuracy: 0.2300 - val_loss: -338.8307\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 43ms/step - accuracy: 0.2450 - loss: -309.5451 - val_accuracy: 0.2300 - val_loss: -341.4798\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2538 - loss: -309.8973 - val_accuracy: 0.2300 - val_loss: -344.1118\n",
            "Training on chunk 26/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2482 - loss: -327.0732 - val_accuracy: 0.2900 - val_loss: -307.9670\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.2343 - loss: -337.5238 - val_accuracy: 0.2900 - val_loss: -310.4150\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.2338 - loss: -345.2260 - val_accuracy: 0.2900 - val_loss: -312.8469\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 53ms/step - accuracy: 0.2523 - loss: -320.9265 - val_accuracy: 0.2900 - val_loss: -315.2787\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.2395 - loss: -350.8625 - val_accuracy: 0.2900 - val_loss: -317.7059\n",
            "Training on chunk 27/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2612 - loss: -327.5495 - val_accuracy: 0.2300 - val_loss: -349.2953\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.2379 - loss: -347.3118 - val_accuracy: 0.2300 - val_loss: -351.9026\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.2570 - loss: -347.5705 - val_accuracy: 0.2300 - val_loss: -354.4968\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 43ms/step - accuracy: 0.2593 - loss: -334.2208 - val_accuracy: 0.2300 - val_loss: -357.0968\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2663 - loss: -345.6281 - val_accuracy: 0.2300 - val_loss: -359.7090\n",
            "Training on chunk 28/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.2716 - loss: -331.9731 - val_accuracy: 0.2500 - val_loss: -348.2955\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 46ms/step - accuracy: 0.2754 - loss: -339.9059 - val_accuracy: 0.2500 - val_loss: -350.7649\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2799 - loss: -330.3276 - val_accuracy: 0.2500 - val_loss: -353.2488\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2762 - loss: -338.9119 - val_accuracy: 0.2500 - val_loss: -355.7282\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.2816 - loss: -325.2719 - val_accuracy: 0.2500 - val_loss: -358.2020\n",
            "Training on chunk 29/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.3062 - loss: -324.6242 - val_accuracy: 0.2400 - val_loss: -359.4066\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.2946 - loss: -326.6363 - val_accuracy: 0.2400 - val_loss: -361.8241\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.3138 - loss: -321.4184 - val_accuracy: 0.2400 - val_loss: -364.2513\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 45ms/step - accuracy: 0.2807 - loss: -345.0501 - val_accuracy: 0.2400 - val_loss: -366.6969\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.3054 - loss: -346.5488 - val_accuracy: 0.2400 - val_loss: -369.1483\n",
            "Training on chunk 30/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2627 - loss: -382.3242 - val_accuracy: 0.2200 - val_loss: -382.9413\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.2425 - loss: -388.9752 - val_accuracy: 0.2200 - val_loss: -385.6099\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.2930 - loss: -365.7361 - val_accuracy: 0.2200 - val_loss: -388.2781\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2461 - loss: -397.5959 - val_accuracy: 0.2200 - val_loss: -390.8909\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2673 - loss: -392.3734 - val_accuracy: 0.2200 - val_loss: -393.5103\n",
            "Training on chunk 31/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.2333 - loss: -390.2604 - val_accuracy: 0.2750 - val_loss: -400.0178\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2358 - loss: -396.2212 - val_accuracy: 0.2750 - val_loss: -402.6718\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2390 - loss: -399.0679 - val_accuracy: 0.2750 - val_loss: -405.3198\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.2718 - loss: -366.5104 - val_accuracy: 0.2750 - val_loss: -407.9453\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2563 - loss: -389.5805 - val_accuracy: 0.2750 - val_loss: -410.5995\n",
            "Training on chunk 32/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2921 - loss: -368.6364 - val_accuracy: 0.2800 - val_loss: -411.8069\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.3082 - loss: -367.5317 - val_accuracy: 0.2800 - val_loss: -414.3754\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2444 - loss: -396.7468 - val_accuracy: 0.2800 - val_loss: -416.9421\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2621 - loss: -408.1406 - val_accuracy: 0.2800 - val_loss: -419.5147\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.2616 - loss: -394.2145 - val_accuracy: 0.2800 - val_loss: -422.0781\n",
            "Training on chunk 33/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2345 - loss: -417.8221 - val_accuracy: 0.2100 - val_loss: -423.4469\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.2369 - loss: -421.3905 - val_accuracy: 0.2100 - val_loss: -426.1365\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.1968 - loss: -444.1979 - val_accuracy: 0.2100 - val_loss: -428.8251\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2272 - loss: -441.9939 - val_accuracy: 0.2100 - val_loss: -431.5152\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.2374 - loss: -420.9017 - val_accuracy: 0.2100 - val_loss: -434.1656\n",
            "Training on chunk 34/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2181 - loss: -419.7091 - val_accuracy: 0.2450 - val_loss: -438.0671\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.2542 - loss: -411.8689 - val_accuracy: 0.2450 - val_loss: -440.5384\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 47ms/step - accuracy: 0.2544 - loss: -389.8073 - val_accuracy: 0.2450 - val_loss: -443.0415\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2747 - loss: -404.6521 - val_accuracy: 0.2450 - val_loss: -445.5663\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 50ms/step - accuracy: 0.2764 - loss: -396.4495 - val_accuracy: 0.2450 - val_loss: -448.1006\n",
            "Training on chunk 35/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.2737 - loss: -421.0994 - val_accuracy: 0.2750 - val_loss: -423.0112\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2578 - loss: -439.0392 - val_accuracy: 0.2750 - val_loss: -425.4789\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.2462 - loss: -441.6260 - val_accuracy: 0.2750 - val_loss: -427.9363\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.2497 - loss: -445.6586 - val_accuracy: 0.2750 - val_loss: -430.3770\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2610 - loss: -432.3093 - val_accuracy: 0.2750 - val_loss: -432.8041\n",
            "Training on chunk 36/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 45ms/step - accuracy: 0.2520 - loss: -453.3508 - val_accuracy: 0.1900 - val_loss: -468.2721\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2457 - loss: -447.3083 - val_accuracy: 0.1900 - val_loss: -470.8927\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.2319 - loss: -450.3921 - val_accuracy: 0.1900 - val_loss: -473.5203\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.2352 - loss: -468.1624 - val_accuracy: 0.1900 - val_loss: -476.1593\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2301 - loss: -476.4667 - val_accuracy: 0.1900 - val_loss: -478.7650\n",
            "Training on chunk 37/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.2415 - loss: -469.0753 - val_accuracy: 0.3000 - val_loss: -427.4007\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.2725 - loss: -451.0673 - val_accuracy: 0.3000 - val_loss: -429.7633\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2262 - loss: -471.3785 - val_accuracy: 0.3000 - val_loss: -432.0958\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.2445 - loss: -476.8669 - val_accuracy: 0.3000 - val_loss: -434.4384\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.2613 - loss: -454.0232 - val_accuracy: 0.3000 - val_loss: -436.8033\n",
            "Training on chunk 38/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.1964 - loss: -503.9205 - val_accuracy: 0.2500 - val_loss: -461.4518\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.2373 - loss: -486.4803 - val_accuracy: 0.2500 - val_loss: -463.9794\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step - accuracy: 0.2365 - loss: -475.1331 - val_accuracy: 0.2500 - val_loss: -466.5067\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2181 - loss: -519.1384 - val_accuracy: 0.2500 - val_loss: -469.0373\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 47ms/step - accuracy: 0.2603 - loss: -480.6537 - val_accuracy: 0.2500 - val_loss: -471.5381\n",
            "Training on chunk 39/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2559 - loss: -486.7364 - val_accuracy: 0.2500 - val_loss: -511.4553\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.2753 - loss: -496.7819 - val_accuracy: 0.2500 - val_loss: -514.0745\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.2335 - loss: -497.8532 - val_accuracy: 0.2500 - val_loss: -516.7070\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2212 - loss: -513.6755 - val_accuracy: 0.2500 - val_loss: -519.3618\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2761 - loss: -488.8380 - val_accuracy: 0.2500 - val_loss: -521.9781\n",
            "Training on chunk 40/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2563 - loss: -497.5982 - val_accuracy: 0.2550 - val_loss: -501.1970\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.2358 - loss: -504.3854 - val_accuracy: 0.2550 - val_loss: -503.6809\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2488 - loss: -506.5486 - val_accuracy: 0.2550 - val_loss: -506.1852\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.2507 - loss: -495.5719 - val_accuracy: 0.2550 - val_loss: -508.6772\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2451 - loss: -500.8979 - val_accuracy: 0.2550 - val_loss: -511.1859\n",
            "Training on chunk 41/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2364 - loss: -526.9234 - val_accuracy: 0.2300 - val_loss: -515.4122\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2664 - loss: -495.5104 - val_accuracy: 0.2300 - val_loss: -517.9136\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.2600 - loss: -508.1339 - val_accuracy: 0.2300 - val_loss: -520.4326\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2420 - loss: -515.9203 - val_accuracy: 0.2300 - val_loss: -522.9622\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.2035 - loss: -543.3564 - val_accuracy: 0.2300 - val_loss: -525.4940\n",
            "Training on chunk 42/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 47ms/step - accuracy: 0.2619 - loss: -528.6227 - val_accuracy: 0.2900 - val_loss: -494.7260\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.2586 - loss: -533.0416 - val_accuracy: 0.2900 - val_loss: -497.1082\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.2465 - loss: -545.8466 - val_accuracy: 0.2900 - val_loss: -499.5196\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.2669 - loss: -539.1774 - val_accuracy: 0.2900 - val_loss: -501.8792\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 51ms/step - accuracy: 0.2776 - loss: -516.7968 - val_accuracy: 0.2900 - val_loss: -504.2741\n",
            "Training on chunk 43/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2662 - loss: -537.4324 - val_accuracy: 0.2850 - val_loss: -533.6253\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2387 - loss: -547.1859 - val_accuracy: 0.2850 - val_loss: -536.1651\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.2298 - loss: -576.6689 - val_accuracy: 0.2850 - val_loss: -538.6806\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 50ms/step - accuracy: 0.2412 - loss: -543.4967 - val_accuracy: 0.2850 - val_loss: -541.1815\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2455 - loss: -542.4310 - val_accuracy: 0.2850 - val_loss: -543.7201\n",
            "Training on chunk 44/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2501 - loss: -551.0840 - val_accuracy: 0.2950 - val_loss: -564.6281\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.2335 - loss: -570.5598 - val_accuracy: 0.2950 - val_loss: -567.2392\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.2411 - loss: -572.4401 - val_accuracy: 0.2950 - val_loss: -569.8339\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.2697 - loss: -540.6298 - val_accuracy: 0.2950 - val_loss: -572.4563\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2394 - loss: -569.3030 - val_accuracy: 0.2950 - val_loss: -575.0658\n",
            "Training on chunk 45/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2273 - loss: -570.5984 - val_accuracy: 0.2500 - val_loss: -553.1889\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.2530 - loss: -583.6848 - val_accuracy: 0.2500 - val_loss: -555.6661\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.2509 - loss: -554.4911 - val_accuracy: 0.2500 - val_loss: -558.1331\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2671 - loss: -551.9109 - val_accuracy: 0.2500 - val_loss: -560.6128\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2705 - loss: -567.3555 - val_accuracy: 0.2500 - val_loss: -563.0935\n",
            "Training on chunk 46/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.2604 - loss: -559.9750 - val_accuracy: 0.2900 - val_loss: -575.1259\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2246 - loss: -578.4336 - val_accuracy: 0.2900 - val_loss: -577.5609\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.2739 - loss: -552.8845 - val_accuracy: 0.2900 - val_loss: -580.0273\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2568 - loss: -565.4741 - val_accuracy: 0.2900 - val_loss: -582.4876\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2442 - loss: -559.0357 - val_accuracy: 0.2900 - val_loss: -584.9786\n",
            "Training on chunk 47/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2361 - loss: -603.3785 - val_accuracy: 0.2350 - val_loss: -615.0692\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.2319 - loss: -582.9924 - val_accuracy: 0.2350 - val_loss: -617.7239\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.2400 - loss: -604.6730 - val_accuracy: 0.2350 - val_loss: -620.4124\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.2448 - loss: -583.8937 - val_accuracy: 0.2350 - val_loss: -623.0851\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.2145 - loss: -619.9143 - val_accuracy: 0.2350 - val_loss: -625.7559\n",
            "Training on chunk 48/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.2364 - loss: -625.8569 - val_accuracy: 0.3100 - val_loss: -522.0787\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2559 - loss: -595.2833 - val_accuracy: 0.3100 - val_loss: -524.3446\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.2547 - loss: -612.3841 - val_accuracy: 0.3100 - val_loss: -526.5876\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.1982 - loss: -668.0625 - val_accuracy: 0.3100 - val_loss: -528.8563\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 57ms/step - accuracy: 0.2367 - loss: -642.0829 - val_accuracy: 0.3100 - val_loss: -531.0813\n",
            "Training on chunk 49/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.2761 - loss: -575.8715 - val_accuracy: 0.1900 - val_loss: -705.4643\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.2696 - loss: -590.2062 - val_accuracy: 0.1900 - val_loss: -708.2651\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 53ms/step - accuracy: 0.2956 - loss: -574.7156 - val_accuracy: 0.1900 - val_loss: -711.0717\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.2798 - loss: -581.5749 - val_accuracy: 0.1900 - val_loss: -713.8967\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2903 - loss: -582.2677 - val_accuracy: 0.1900 - val_loss: -716.7531\n",
            "Training on chunk 50/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2477 - loss: -628.5383 - val_accuracy: 0.2300 - val_loss: -658.9722\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2641 - loss: -624.2835 - val_accuracy: 0.2300 - val_loss: -661.6412\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.2493 - loss: -609.0048 - val_accuracy: 0.2300 - val_loss: -664.2805\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2492 - loss: -611.4518 - val_accuracy: 0.2300 - val_loss: -666.9511\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.2448 - loss: -642.7563 - val_accuracy: 0.2300 - val_loss: -669.6010\n",
            "Training on chunk 51/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.2665 - loss: -638.7635 - val_accuracy: 0.2700 - val_loss: -638.1266\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.2679 - loss: -638.5574 - val_accuracy: 0.2700 - val_loss: -640.6174\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2773 - loss: -623.8906 - val_accuracy: 0.2700 - val_loss: -643.1362\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.2497 - loss: -625.9868 - val_accuracy: 0.2700 - val_loss: -645.6551\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.2529 - loss: -639.9525 - val_accuracy: 0.2700 - val_loss: -648.1612\n",
            "Training on chunk 52/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2381 - loss: -672.4108 - val_accuracy: 0.2600 - val_loss: -620.2521\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.2280 - loss: -654.7156 - val_accuracy: 0.2600 - val_loss: -622.6838\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.2214 - loss: -647.0901 - val_accuracy: 0.2600 - val_loss: -625.1016\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 52ms/step - accuracy: 0.2425 - loss: -657.2610 - val_accuracy: 0.2600 - val_loss: -627.5137\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.2489 - loss: -635.9533 - val_accuracy: 0.2600 - val_loss: -629.9637\n",
            "Training on chunk 53/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2415 - loss: -669.9196 - val_accuracy: 0.2450 - val_loss: -670.0888\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2468 - loss: -656.6724 - val_accuracy: 0.2450 - val_loss: -672.6390\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2590 - loss: -641.4755 - val_accuracy: 0.2450 - val_loss: -675.1862\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2634 - loss: -658.9804 - val_accuracy: 0.2450 - val_loss: -677.7594\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 51ms/step - accuracy: 0.2396 - loss: -705.1464 - val_accuracy: 0.2450 - val_loss: -680.2943\n",
            "Training on chunk 54/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2591 - loss: -700.0654 - val_accuracy: 0.2400 - val_loss: -685.1359\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.2583 - loss: -654.2645 - val_accuracy: 0.2400 - val_loss: -687.7177\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2794 - loss: -673.1329 - val_accuracy: 0.2400 - val_loss: -690.3024\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2530 - loss: -695.4551 - val_accuracy: 0.2400 - val_loss: -692.9008\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.2405 - loss: -721.4313 - val_accuracy: 0.2400 - val_loss: -695.4764\n",
            "Training on chunk 55/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2766 - loss: -674.9438 - val_accuracy: 0.2400 - val_loss: -711.7795\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 55ms/step - accuracy: 0.2975 - loss: -670.0290 - val_accuracy: 0.2400 - val_loss: -714.3055\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 46ms/step - accuracy: 0.2611 - loss: -702.6264 - val_accuracy: 0.2400 - val_loss: -716.8469\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.2778 - loss: -669.1565 - val_accuracy: 0.2400 - val_loss: -719.3889\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2825 - loss: -637.4529 - val_accuracy: 0.2400 - val_loss: -721.9691\n",
            "Training on chunk 56/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.2515 - loss: -703.3246 - val_accuracy: 0.2700 - val_loss: -677.6652\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2691 - loss: -678.0087 - val_accuracy: 0.2700 - val_loss: -680.0979\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2542 - loss: -702.4023 - val_accuracy: 0.2700 - val_loss: -682.5291\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.2608 - loss: -686.8221 - val_accuracy: 0.2700 - val_loss: -684.9460\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.2210 - loss: -731.1779 - val_accuracy: 0.2700 - val_loss: -687.3687\n",
            "Training on chunk 57/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2937 - loss: -696.1212 - val_accuracy: 0.2900 - val_loss: -708.9189\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 45ms/step - accuracy: 0.2674 - loss: -721.2317 - val_accuracy: 0.2900 - val_loss: -711.4113\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 51ms/step - accuracy: 0.2674 - loss: -734.3387 - val_accuracy: 0.2900 - val_loss: -713.8979\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2965 - loss: -682.8459 - val_accuracy: 0.2900 - val_loss: -716.4031\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2775 - loss: -727.9474 - val_accuracy: 0.2900 - val_loss: -718.8770\n",
            "Training on chunk 58/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - accuracy: 0.2505 - loss: -727.1950 - val_accuracy: 0.2500 - val_loss: -733.6029\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.2202 - loss: -768.8548 - val_accuracy: 0.2500 - val_loss: -736.1942\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.2595 - loss: -737.4147 - val_accuracy: 0.2500 - val_loss: -738.7653\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 57ms/step - accuracy: 0.2445 - loss: -753.4230 - val_accuracy: 0.2500 - val_loss: -741.3438\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2443 - loss: -737.7383 - val_accuracy: 0.2500 - val_loss: -743.9232\n",
            "Training on chunk 59/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2584 - loss: -730.1490 - val_accuracy: 0.2650 - val_loss: -751.3747\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - accuracy: 0.2225 - loss: -758.9901 - val_accuracy: 0.2650 - val_loss: -753.8738\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.2450 - loss: -734.4221 - val_accuracy: 0.2650 - val_loss: -756.3864\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2335 - loss: -747.4720 - val_accuracy: 0.2650 - val_loss: -758.9485\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2546 - loss: -726.3920 - val_accuracy: 0.2650 - val_loss: -761.4508\n",
            "Training on chunk 60/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2463 - loss: -748.6114 - val_accuracy: 0.2300 - val_loss: -784.1968\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2447 - loss: -763.8404 - val_accuracy: 0.2300 - val_loss: -786.8753\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2577 - loss: -771.9228 - val_accuracy: 0.2300 - val_loss: -789.5632\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.2423 - loss: -767.7125 - val_accuracy: 0.2300 - val_loss: -792.2238\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2101 - loss: -777.2668 - val_accuracy: 0.2300 - val_loss: -794.8719\n",
            "Training on chunk 61/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2591 - loss: -741.2937 - val_accuracy: 0.2750 - val_loss: -723.3415\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2678 - loss: -723.7878 - val_accuracy: 0.2750 - val_loss: -725.6772\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2648 - loss: -726.5172 - val_accuracy: 0.2750 - val_loss: -728.0140\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2225 - loss: -788.0408 - val_accuracy: 0.2750 - val_loss: -730.3831\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2436 - loss: -780.9686 - val_accuracy: 0.2750 - val_loss: -732.7386\n",
            "Training on chunk 62/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2365 - loss: -796.9577 - val_accuracy: 0.2250 - val_loss: -768.9215\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.2448 - loss: -793.8796 - val_accuracy: 0.2250 - val_loss: -771.4771\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 56ms/step - accuracy: 0.2642 - loss: -770.5356 - val_accuracy: 0.2250 - val_loss: -774.0002\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.2645 - loss: -774.3251 - val_accuracy: 0.2250 - val_loss: -776.5355\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.2511 - loss: -787.6974 - val_accuracy: 0.2250 - val_loss: -779.0682\n",
            "Training on chunk 63/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2609 - loss: -782.7548 - val_accuracy: 0.2900 - val_loss: -702.3279\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2865 - loss: -734.1248 - val_accuracy: 0.2900 - val_loss: -704.5539\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2615 - loss: -804.3311 - val_accuracy: 0.2900 - val_loss: -706.7954\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2723 - loss: -781.0947 - val_accuracy: 0.2900 - val_loss: -709.0380\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.2430 - loss: -774.0294 - val_accuracy: 0.2900 - val_loss: -711.2651\n",
            "Training on chunk 64/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2720 - loss: -763.3094 - val_accuracy: 0.2550 - val_loss: -850.3137\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.2587 - loss: -777.6866 - val_accuracy: 0.2550 - val_loss: -852.9545\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2565 - loss: -776.6558 - val_accuracy: 0.2550 - val_loss: -855.6295\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2660 - loss: -774.1854 - val_accuracy: 0.2550 - val_loss: -858.2557\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.2584 - loss: -797.5270 - val_accuracy: 0.2550 - val_loss: -860.9319\n",
            "Training on chunk 65/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2424 - loss: -808.9091 - val_accuracy: 0.2350 - val_loss: -781.8483\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2507 - loss: -804.7018 - val_accuracy: 0.2350 - val_loss: -784.2498\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2504 - loss: -805.1099 - val_accuracy: 0.2350 - val_loss: -786.6555\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 49ms/step - accuracy: 0.2645 - loss: -798.5074 - val_accuracy: 0.2350 - val_loss: -789.0551\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2221 - loss: -836.3658 - val_accuracy: 0.2350 - val_loss: -791.4573\n",
            "Training on chunk 66/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.2584 - loss: -829.2841 - val_accuracy: 0.2800 - val_loss: -771.7321\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.2507 - loss: -851.0302 - val_accuracy: 0.2800 - val_loss: -774.0635\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2809 - loss: -814.4702 - val_accuracy: 0.2800 - val_loss: -776.4045\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 48ms/step - accuracy: 0.2492 - loss: -836.5671 - val_accuracy: 0.2800 - val_loss: -778.7513\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 56ms/step - accuracy: 0.2686 - loss: -803.4781 - val_accuracy: 0.2800 - val_loss: -781.0818\n",
            "Training on chunk 67/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2800 - loss: -812.0097 - val_accuracy: 0.2600 - val_loss: -870.4928\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2636 - loss: -832.3007 - val_accuracy: 0.2600 - val_loss: -873.1498\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 48ms/step - accuracy: 0.2541 - loss: -880.1592 - val_accuracy: 0.2600 - val_loss: -875.7639\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2845 - loss: -836.0391 - val_accuracy: 0.2600 - val_loss: -878.3695\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.2610 - loss: -845.4585 - val_accuracy: 0.2600 - val_loss: -880.9888\n",
            "Training on chunk 68/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2753 - loss: -814.0897 - val_accuracy: 0.2350 - val_loss: -852.2122\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2749 - loss: -833.5969 - val_accuracy: 0.2350 - val_loss: -854.7062\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2731 - loss: -841.3716 - val_accuracy: 0.2350 - val_loss: -857.2068\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2477 - loss: -853.9924 - val_accuracy: 0.2350 - val_loss: -859.7067\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2735 - loss: -836.7577 - val_accuracy: 0.2350 - val_loss: -862.2264\n",
            "Training on chunk 69/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.1977 - loss: -938.1617 - val_accuracy: 0.2600 - val_loss: -830.1509\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2292 - loss: -884.6719 - val_accuracy: 0.2600 - val_loss: -832.6644\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.1972 - loss: -956.0383 - val_accuracy: 0.2600 - val_loss: -835.1584\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2045 - loss: -949.4576 - val_accuracy: 0.2600 - val_loss: -837.6546\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 50ms/step - accuracy: 0.2179 - loss: -905.8937 - val_accuracy: 0.2600 - val_loss: -840.1311\n",
            "Training on chunk 70/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 52ms/step - accuracy: 0.2496 - loss: -903.4834 - val_accuracy: 0.2600 - val_loss: -874.8002\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2439 - loss: -884.5955 - val_accuracy: 0.2600 - val_loss: -877.2903\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 48ms/step - accuracy: 0.2458 - loss: -901.3090 - val_accuracy: 0.2600 - val_loss: -879.7728\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.2689 - loss: -847.9677 - val_accuracy: 0.2600 - val_loss: -882.2523\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2424 - loss: -896.0966 - val_accuracy: 0.2600 - val_loss: -884.7541\n",
            "Training on chunk 71/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2355 - loss: -904.0533 - val_accuracy: 0.2650 - val_loss: -866.4578\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2516 - loss: -920.9996 - val_accuracy: 0.2650 - val_loss: -868.9449\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.2558 - loss: -900.3737 - val_accuracy: 0.2650 - val_loss: -871.4253\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2198 - loss: -962.9512 - val_accuracy: 0.2650 - val_loss: -873.8839\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2429 - loss: -946.5096 - val_accuracy: 0.2650 - val_loss: -876.3531\n",
            "Training on chunk 72/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2468 - loss: -931.9940 - val_accuracy: 0.2600 - val_loss: -845.5541\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2761 - loss: -899.6395 - val_accuracy: 0.2600 - val_loss: -847.9101\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2671 - loss: -917.2286 - val_accuracy: 0.2600 - val_loss: -850.2508\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2719 - loss: -894.4120 - val_accuracy: 0.2600 - val_loss: -852.5940\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.2640 - loss: -912.1352 - val_accuracy: 0.2600 - val_loss: -854.9441\n",
            "Training on chunk 73/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2472 - loss: -917.9886 - val_accuracy: 0.2600 - val_loss: -866.5248\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2173 - loss: -967.5724 - val_accuracy: 0.2600 - val_loss: -868.9417\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 54ms/step - accuracy: 0.2326 - loss: -946.0230 - val_accuracy: 0.2600 - val_loss: -871.3306\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2344 - loss: -958.4772 - val_accuracy: 0.2600 - val_loss: -873.7492\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2297 - loss: -977.5347 - val_accuracy: 0.2600 - val_loss: -876.1520\n",
            "Training on chunk 74/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2591 - loss: -943.8311 - val_accuracy: 0.2500 - val_loss: -943.6260\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.2778 - loss: -908.2773 - val_accuracy: 0.2500 - val_loss: -946.1010\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.2762 - loss: -908.3274 - val_accuracy: 0.2500 - val_loss: -948.5822\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.2667 - loss: -919.5538 - val_accuracy: 0.2500 - val_loss: -951.1116\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2530 - loss: -914.2542 - val_accuracy: 0.2500 - val_loss: -953.6180\n",
            "Training on chunk 75/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.3207 - loss: -856.8630 - val_accuracy: 0.2100 - val_loss: -981.2369\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 57ms/step - accuracy: 0.2740 - loss: -902.5718 - val_accuracy: 0.2100 - val_loss: -983.7937\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2757 - loss: -914.9521 - val_accuracy: 0.2100 - val_loss: -986.3442\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2672 - loss: -904.1584 - val_accuracy: 0.2100 - val_loss: -988.9210\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2980 - loss: -881.2053 - val_accuracy: 0.2100 - val_loss: -991.4891\n",
            "Training on chunk 76/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2382 - loss: -986.7088 - val_accuracy: 0.2400 - val_loss: -933.6586\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 49ms/step - accuracy: 0.2629 - loss: -946.4598 - val_accuracy: 0.2400 - val_loss: -936.2097\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2529 - loss: -993.6589 - val_accuracy: 0.2400 - val_loss: -938.7368\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 49ms/step - accuracy: 0.2469 - loss: -966.6335 - val_accuracy: 0.2400 - val_loss: -941.2442\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2458 - loss: -961.8995 - val_accuracy: 0.2400 - val_loss: -943.7562\n",
            "Training on chunk 77/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2189 - loss: -1000.4822 - val_accuracy: 0.2600 - val_loss: -884.9045\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2417 - loss: -988.1035 - val_accuracy: 0.2600 - val_loss: -887.2628\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2544 - loss: -991.1257 - val_accuracy: 0.2600 - val_loss: -889.5901\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.2297 - loss: -1000.8702 - val_accuracy: 0.2600 - val_loss: -891.9258\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2418 - loss: -993.8839 - val_accuracy: 0.2600 - val_loss: -894.2530\n",
            "Training on chunk 78/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2474 - loss: -970.4047 - val_accuracy: 0.2350 - val_loss: -1024.1904\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2457 - loss: -983.5219 - val_accuracy: 0.2350 - val_loss: -1026.8322\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2387 - loss: -1005.6834 - val_accuracy: 0.2350 - val_loss: -1029.4829\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 56ms/step - accuracy: 0.2531 - loss: -968.0048 - val_accuracy: 0.2350 - val_loss: -1032.1305\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2470 - loss: -997.1063 - val_accuracy: 0.2350 - val_loss: -1034.7828\n",
            "Training on chunk 79/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2663 - loss: -964.7798 - val_accuracy: 0.2000 - val_loss: -1123.5201\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2802 - loss: -959.2485 - val_accuracy: 0.2000 - val_loss: -1126.3127\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2630 - loss: -997.8655 - val_accuracy: 0.2000 - val_loss: -1129.0978\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 52ms/step - accuracy: 0.2722 - loss: -979.2350 - val_accuracy: 0.2000 - val_loss: -1131.9104\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 58ms/step - accuracy: 0.2620 - loss: -975.0091 - val_accuracy: 0.2000 - val_loss: -1134.7234\n",
            "Training on chunk 80/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2646 - loss: -1030.2847 - val_accuracy: 0.2700 - val_loss: -946.3379\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.2545 - loss: -1027.4149 - val_accuracy: 0.2700 - val_loss: -948.7611\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2719 - loss: -976.8674 - val_accuracy: 0.2700 - val_loss: -951.1816\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 49ms/step - accuracy: 0.2618 - loss: -1023.1195 - val_accuracy: 0.2700 - val_loss: -953.5991\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2420 - loss: -1040.7151 - val_accuracy: 0.2700 - val_loss: -956.0239\n",
            "Training on chunk 81/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.2251 - loss: -1050.2921 - val_accuracy: 0.3050 - val_loss: -931.2757\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 52ms/step - accuracy: 0.2631 - loss: -982.8405 - val_accuracy: 0.3050 - val_loss: -933.6465\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2484 - loss: -1039.9493 - val_accuracy: 0.3050 - val_loss: -936.0073\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2373 - loss: -1065.9290 - val_accuracy: 0.3050 - val_loss: -938.3748\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.2537 - loss: -1051.9106 - val_accuracy: 0.3050 - val_loss: -940.7171\n",
            "Training on chunk 82/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 55ms/step - accuracy: 0.2382 - loss: -1059.3373 - val_accuracy: 0.2950 - val_loss: -1001.5344\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2554 - loss: -1012.7679 - val_accuracy: 0.2950 - val_loss: -1003.9645\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.2576 - loss: -1020.1066 - val_accuracy: 0.2950 - val_loss: -1006.3886\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2687 - loss: -1019.3148 - val_accuracy: 0.2950 - val_loss: -1008.8192\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 61ms/step - accuracy: 0.2373 - loss: -1023.7197 - val_accuracy: 0.2950 - val_loss: -1011.2831\n",
            "Training on chunk 83/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2748 - loss: -1033.4685 - val_accuracy: 0.2800 - val_loss: -992.8173\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2634 - loss: -1071.5592 - val_accuracy: 0.2800 - val_loss: -995.2148\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2657 - loss: -1043.8428 - val_accuracy: 0.2800 - val_loss: -997.6114\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.2670 - loss: -1073.0305 - val_accuracy: 0.2800 - val_loss: -1000.0044\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2486 - loss: -1059.3218 - val_accuracy: 0.2800 - val_loss: -1002.4073\n",
            "Training on chunk 84/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2694 - loss: -1028.7487 - val_accuracy: 0.2150 - val_loss: -1174.0031\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.2664 - loss: -1041.3318 - val_accuracy: 0.2150 - val_loss: -1176.7594\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2623 - loss: -1060.3510 - val_accuracy: 0.2150 - val_loss: -1179.5408\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.2664 - loss: -1060.9075 - val_accuracy: 0.2150 - val_loss: -1182.3203\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2418 - loss: -1125.2660 - val_accuracy: 0.2150 - val_loss: -1185.1071\n",
            "Training on chunk 85/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2118 - loss: -1074.7955 - val_accuracy: 0.2300 - val_loss: -1109.4756\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2163 - loss: -1081.0236 - val_accuracy: 0.2300 - val_loss: -1112.0989\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.2167 - loss: -1094.9667 - val_accuracy: 0.2300 - val_loss: -1114.7452\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 53ms/step - accuracy: 0.2238 - loss: -1104.4606 - val_accuracy: 0.2300 - val_loss: -1117.4055\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.1941 - loss: -1093.3915 - val_accuracy: 0.2300 - val_loss: -1120.0490\n",
            "Training on chunk 86/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2571 - loss: -1084.5496 - val_accuracy: 0.2700 - val_loss: -1039.6392\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 60ms/step - accuracy: 0.2608 - loss: -1043.1460 - val_accuracy: 0.2700 - val_loss: -1042.0839\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2586 - loss: -1056.8195 - val_accuracy: 0.2700 - val_loss: -1044.5179\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.2403 - loss: -1093.5018 - val_accuracy: 0.2700 - val_loss: -1046.9702\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2564 - loss: -1099.5137 - val_accuracy: 0.2700 - val_loss: -1049.3979\n",
            "Training on chunk 87/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2768 - loss: -1060.9608 - val_accuracy: 0.2500 - val_loss: -1099.2515\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2844 - loss: -1018.9495 - val_accuracy: 0.2500 - val_loss: -1101.7112\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.2755 - loss: -997.2986 - val_accuracy: 0.2500 - val_loss: -1104.2069\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2567 - loss: -1085.2158 - val_accuracy: 0.2500 - val_loss: -1106.7124\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2424 - loss: -1103.7240 - val_accuracy: 0.2500 - val_loss: -1109.2258\n",
            "Training on chunk 88/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 62ms/step - accuracy: 0.2922 - loss: -1010.1788 - val_accuracy: 0.2550 - val_loss: -1089.5977\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.2748 - loss: -1071.3970 - val_accuracy: 0.2550 - val_loss: -1092.1017\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.2553 - loss: -1085.8185 - val_accuracy: 0.2550 - val_loss: -1094.5789\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2538 - loss: -1106.4268 - val_accuracy: 0.2550 - val_loss: -1097.0864\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2299 - loss: -1170.4076 - val_accuracy: 0.2550 - val_loss: -1099.5687\n",
            "Training on chunk 89/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2297 - loss: -1153.6212 - val_accuracy: 0.3200 - val_loss: -1008.6368\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.2514 - loss: -1117.4747 - val_accuracy: 0.3200 - val_loss: -1010.8928\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 59ms/step - accuracy: 0.2474 - loss: -1119.2983 - val_accuracy: 0.3200 - val_loss: -1013.1617\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2613 - loss: -1100.0989 - val_accuracy: 0.3200 - val_loss: -1015.4434\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step - accuracy: 0.2538 - loss: -1096.1530 - val_accuracy: 0.3200 - val_loss: -1017.7100\n",
            "Training on chunk 90/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.2296 - loss: -1171.8156 - val_accuracy: 0.2500 - val_loss: -1137.1542\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2608 - loss: -1105.4591 - val_accuracy: 0.2500 - val_loss: -1139.7255\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 60ms/step - accuracy: 0.2713 - loss: -1100.5203 - val_accuracy: 0.2500 - val_loss: -1142.2965\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 53ms/step - accuracy: 0.2505 - loss: -1139.5701 - val_accuracy: 0.2500 - val_loss: -1144.8684\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 59ms/step - accuracy: 0.2594 - loss: -1127.8734 - val_accuracy: 0.2500 - val_loss: -1147.4110\n",
            "Training on chunk 91/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2506 - loss: -1131.7012 - val_accuracy: 0.2200 - val_loss: -1119.3657\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 57ms/step - accuracy: 0.2641 - loss: -1134.8564 - val_accuracy: 0.2200 - val_loss: -1121.7905\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 58ms/step - accuracy: 0.2369 - loss: -1187.9165 - val_accuracy: 0.2200 - val_loss: -1124.2278\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2611 - loss: -1110.7048 - val_accuracy: 0.2200 - val_loss: -1126.6710\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.2551 - loss: -1133.0664 - val_accuracy: 0.2200 - val_loss: -1129.1101\n",
            "Training on chunk 92/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.2789 - loss: -1098.2648 - val_accuracy: 0.2550 - val_loss: -1166.2826\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 49ms/step - accuracy: 0.2587 - loss: -1171.9279 - val_accuracy: 0.2550 - val_loss: -1168.8109\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2825 - loss: -1092.5107 - val_accuracy: 0.2550 - val_loss: -1171.3082\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 59ms/step - accuracy: 0.2565 - loss: -1127.9194 - val_accuracy: 0.2550 - val_loss: -1173.8210\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2489 - loss: -1132.2489 - val_accuracy: 0.2550 - val_loss: -1176.3303\n",
            "Training on chunk 93/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2402 - loss: -1227.9758 - val_accuracy: 0.2100 - val_loss: -1296.1001\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 51ms/step - accuracy: 0.2359 - loss: -1193.8350 - val_accuracy: 0.2100 - val_loss: -1299.0106\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 54ms/step - accuracy: 0.2500 - loss: -1223.2135 - val_accuracy: 0.2100 - val_loss: -1301.8773\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2411 - loss: -1204.4237 - val_accuracy: 0.2100 - val_loss: -1304.7079\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 48ms/step - accuracy: 0.2573 - loss: -1182.8979 - val_accuracy: 0.2100 - val_loss: -1307.5947\n",
            "Training on chunk 94/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.2764 - loss: -1124.7314 - val_accuracy: 0.2350 - val_loss: -1152.4862\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 57ms/step - accuracy: 0.2516 - loss: -1156.1724 - val_accuracy: 0.2350 - val_loss: -1154.9335\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 61ms/step - accuracy: 0.2443 - loss: -1168.8402 - val_accuracy: 0.2350 - val_loss: -1157.3917\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 49ms/step - accuracy: 0.2583 - loss: -1184.1229 - val_accuracy: 0.2350 - val_loss: -1159.8585\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 58ms/step - accuracy: 0.2630 - loss: -1200.1556 - val_accuracy: 0.2350 - val_loss: -1162.3145\n",
            "Training on chunk 95/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.2529 - loss: -1167.1453 - val_accuracy: 0.2050 - val_loss: -1312.2708\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - accuracy: 0.2502 - loss: -1139.1218 - val_accuracy: 0.2050 - val_loss: -1314.9893\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 55ms/step - accuracy: 0.2425 - loss: -1183.1989 - val_accuracy: 0.2050 - val_loss: -1317.7301\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - accuracy: 0.2684 - loss: -1154.9711 - val_accuracy: 0.2050 - val_loss: -1320.4465\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.2347 - loss: -1205.1201 - val_accuracy: 0.2050 - val_loss: -1323.2052\n",
            "Training on chunk 96/96\n",
            "Epoch 1/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 60ms/step - accuracy: 0.2294 - loss: -1245.0261 - val_accuracy: 0.2450 - val_loss: -1265.5431\n",
            "Epoch 2/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 50ms/step - accuracy: 0.2310 - loss: -1252.8490 - val_accuracy: 0.2450 - val_loss: -1268.2089\n",
            "Epoch 3/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 56ms/step - accuracy: 0.2350 - loss: -1206.0383 - val_accuracy: 0.2450 - val_loss: -1270.8907\n",
            "Epoch 4/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 61ms/step - accuracy: 0.2381 - loss: -1196.0929 - val_accuracy: 0.2450 - val_loss: -1273.5688\n",
            "Epoch 5/5\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 51ms/step - accuracy: 0.2340 - loss: -1253.4176 - val_accuracy: 0.2450 - val_loss: -1276.2266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "batch_size = 32\n",
        "max_words = 10000\n",
        "embedding_dim = 20\n",
        "lstm_units = 40\n",
        "epochs = 5\n",
        "\n",
        "# Function to split data into chunks\n",
        "def chunk_data(X, y, chunk_size):\n",
        "    num_chunks = len(X) // chunk_size + int(len(X) % chunk_size != 0)\n",
        "    X_chunks = np.array_split(X, num_chunks)\n",
        "    y_chunks = np.array_split(y, num_chunks)\n",
        "    return X_chunks, y_chunks\n",
        "\n",
        "# Initialize the model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
        "    model.add(LSTM(units=lstm_units, return_sequences=True))\n",
        "    model.add(LSTM(units=lstm_units))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Initialize the model for the first chunk\n",
        "model = create_model()\n",
        "\n",
        "# Split the data into chunks\n",
        "chunk_size = 1000  # Define the size of each chunk\n",
        "X_chunks, y_chunks = chunk_data(X_train, y_train, chunk_size)\n",
        "\n",
        "# Iterative training process\n",
        "for i, (X_chunk, y_chunk) in enumerate(zip(X_chunks, y_chunks)):\n",
        "    print(f\"Training on chunk {i+1}/{len(X_chunks)}\")\n",
        "\n",
        "    # Fit the model on the current chunk\n",
        "    model.fit(X_chunk, y_chunk, epochs=epochs, batch_size=batch_size, validation_split=0.2)\n",
        "\n",
        "    # Optionally save the model weights after each chunk\n",
        "    model.save_weights(f\"model_weights_chunk_{i+1}.weights.h5\")"
      ],
      "metadata": {
        "id": "yu6BDLJvx4E5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddda0fbd-6bfd-4d92-e7c0-8522e6ea4fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training on chunk 1/96\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.2508 - loss: -0.3495 - val_accuracy: 0.2350 - val_loss: -7.3736\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2379 - loss: -9.3798 - val_accuracy: 0.2350 - val_loss: -13.3945\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.2448 - loss: -14.3153 - val_accuracy: 0.2350 - val_loss: -16.5945\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.2588 - loss: -17.2948 - val_accuracy: 0.2350 - val_loss: -18.7737\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.2729 - loss: -19.2298 - val_accuracy: 0.2350 - val_loss: -20.6087\n",
            "Training on chunk 2/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2511 - loss: -21.7506 - val_accuracy: 0.2450 - val_loss: -22.4503\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2519 - loss: -23.9373 - val_accuracy: 0.2450 - val_loss: -24.1758\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.2630 - loss: -24.1354 - val_accuracy: 0.2450 - val_loss: -25.8462\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2410 - loss: -27.2698 - val_accuracy: 0.2450 - val_loss: -27.5128\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.2380 - loss: -28.6418 - val_accuracy: 0.2450 - val_loss: -29.1428\n",
            "Training on chunk 3/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2461 - loss: -29.2604 - val_accuracy: 0.2300 - val_loss: -30.4204\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2290 - loss: -32.5173 - val_accuracy: 0.2300 - val_loss: -32.0078\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2525 - loss: -31.9421 - val_accuracy: 0.2300 - val_loss: -33.5245\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.2502 - loss: -33.0393 - val_accuracy: 0.2300 - val_loss: -35.0695\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.2379 - loss: -35.6490 - val_accuracy: 0.2300 - val_loss: -36.6167\n",
            "Training on chunk 4/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2602 - loss: -36.1298 - val_accuracy: 0.2450 - val_loss: -39.1578\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2575 - loss: -38.4348 - val_accuracy: 0.2450 - val_loss: -40.7408\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.2501 - loss: -39.4913 - val_accuracy: 0.2450 - val_loss: -42.2961\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.2591 - loss: -40.7393 - val_accuracy: 0.2450 - val_loss: -43.8659\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.2530 - loss: -42.5118 - val_accuracy: 0.2450 - val_loss: -45.4232\n",
            "Training on chunk 5/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2616 - loss: -43.7645 - val_accuracy: 0.2450 - val_loss: -47.4125\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2855 - loss: -43.6156 - val_accuracy: 0.2450 - val_loss: -48.9306\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2683 - loss: -45.5973 - val_accuracy: 0.2450 - val_loss: -50.4640\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 86ms/step - accuracy: 0.2660 - loss: -48.0799 - val_accuracy: 0.2450 - val_loss: -51.9822\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.2675 - loss: -48.6039 - val_accuracy: 0.2450 - val_loss: -53.5126\n",
            "Training on chunk 6/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2569 - loss: -49.1841 - val_accuracy: 0.2250 - val_loss: -55.9038\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2421 - loss: -52.6759 - val_accuracy: 0.2250 - val_loss: -57.4669\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.2724 - loss: -51.1576 - val_accuracy: 0.2250 - val_loss: -58.9923\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.2595 - loss: -55.7631 - val_accuracy: 0.2250 - val_loss: -60.5592\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.2567 - loss: -56.8828 - val_accuracy: 0.2250 - val_loss: -62.0939\n",
            "Training on chunk 7/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2779 - loss: -55.8476 - val_accuracy: 0.2350 - val_loss: -62.0475\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.2931 - loss: -58.8212 - val_accuracy: 0.2350 - val_loss: -63.6097\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.2893 - loss: -59.6400 - val_accuracy: 0.2350 - val_loss: -65.1440\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.2767 - loss: -62.8449 - val_accuracy: 0.2350 - val_loss: -66.7203\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.2857 - loss: -63.3028 - val_accuracy: 0.2350 - val_loss: -68.2588\n",
            "Training on chunk 8/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.2473 - loss: -67.5094 - val_accuracy: 0.2150 - val_loss: -73.2437\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2733 - loss: -66.0486 - val_accuracy: 0.2150 - val_loss: -74.8770\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.2537 - loss: -69.7354 - val_accuracy: 0.2150 - val_loss: -76.5222\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.2544 - loss: -72.6115 - val_accuracy: 0.2150 - val_loss: -78.1756\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.2189 - loss: -75.8776 - val_accuracy: 0.2150 - val_loss: -79.8168\n",
            "Training on chunk 9/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.2309 - loss: -76.5061 - val_accuracy: 0.2900 - val_loss: -73.1140\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2411 - loss: -77.7146 - val_accuracy: 0.2900 - val_loss: -74.6100\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2422 - loss: -78.5748 - val_accuracy: 0.2900 - val_loss: -76.1070\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2553 - loss: -82.5196 - val_accuracy: 0.2900 - val_loss: -77.5984\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2402 - loss: -82.6088 - val_accuracy: 0.2900 - val_loss: -79.1050\n",
            "Training on chunk 10/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2301 - loss: -83.6953 - val_accuracy: 0.2450 - val_loss: -81.7071\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2170 - loss: -88.2678 - val_accuracy: 0.2450 - val_loss: -83.2565\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2084 - loss: -89.7308 - val_accuracy: 0.2450 - val_loss: -84.7831\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2317 - loss: -88.3522 - val_accuracy: 0.2450 - val_loss: -86.2940\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2115 - loss: -93.6298 - val_accuracy: 0.2450 - val_loss: -87.8166\n",
            "Training on chunk 11/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.2076 - loss: -92.8935 - val_accuracy: 0.2450 - val_loss: -88.7130\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2206 - loss: -94.1636 - val_accuracy: 0.2450 - val_loss: -90.1981\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.2309 - loss: -93.6375 - val_accuracy: 0.2450 - val_loss: -91.6613\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2157 - loss: -97.2022 - val_accuracy: 0.2450 - val_loss: -93.1528\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.2169 - loss: -98.5096 - val_accuracy: 0.2450 - val_loss: -94.6283\n",
            "Training on chunk 12/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.2722 - loss: -92.0010 - val_accuracy: 0.2550 - val_loss: -99.6874\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2361 - loss: -100.9860 - val_accuracy: 0.2550 - val_loss: -101.1778\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2634 - loss: -96.7837 - val_accuracy: 0.2550 - val_loss: -102.6248\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2553 - loss: -100.7949 - val_accuracy: 0.2550 - val_loss: -104.1122\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.2377 - loss: -103.6760 - val_accuracy: 0.2550 - val_loss: -105.5931\n",
            "Training on chunk 13/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2810 - loss: -99.4769 - val_accuracy: 0.2650 - val_loss: -103.5067\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.2527 - loss: -103.4812 - val_accuracy: 0.2650 - val_loss: -104.9534\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2627 - loss: -104.6017 - val_accuracy: 0.2650 - val_loss: -106.3800\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.2708 - loss: -105.1156 - val_accuracy: 0.2650 - val_loss: -107.8073\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2571 - loss: -108.7973 - val_accuracy: 0.2650 - val_loss: -109.2518\n",
            "Training on chunk 14/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2909 - loss: -112.2880 - val_accuracy: 0.2400 - val_loss: -115.6298\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2708 - loss: -117.3754 - val_accuracy: 0.2400 - val_loss: -117.1753\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.2707 - loss: -114.5995 - val_accuracy: 0.2400 - val_loss: -118.6975\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.2676 - loss: -116.9916 - val_accuracy: 0.2400 - val_loss: -120.2151\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.2342 - loss: -124.2867 - val_accuracy: 0.2400 - val_loss: -121.7521\n",
            "Training on chunk 15/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.2381 - loss: -124.4965 - val_accuracy: 0.2400 - val_loss: -122.1016\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2475 - loss: -125.2582 - val_accuracy: 0.2400 - val_loss: -123.6419\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.2410 - loss: -130.4345 - val_accuracy: 0.2400 - val_loss: -125.2199\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.2343 - loss: -130.6456 - val_accuracy: 0.2400 - val_loss: -126.7822\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2292 - loss: -129.2008 - val_accuracy: 0.2400 - val_loss: -128.3386\n",
            "Training on chunk 16/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2568 - loss: -127.1037 - val_accuracy: 0.2250 - val_loss: -139.7806\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.2192 - loss: -131.1215 - val_accuracy: 0.2250 - val_loss: -141.4174\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - accuracy: 0.2173 - loss: -133.2738 - val_accuracy: 0.2250 - val_loss: -143.0566\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.2123 - loss: -137.6001 - val_accuracy: 0.2250 - val_loss: -144.6870\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2440 - loss: -132.1768 - val_accuracy: 0.2250 - val_loss: -146.3191\n",
            "Training on chunk 17/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2249 - loss: -144.8651 - val_accuracy: 0.2100 - val_loss: -147.5278\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2519 - loss: -140.1726 - val_accuracy: 0.2100 - val_loss: -149.1689\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.2443 - loss: -142.1840 - val_accuracy: 0.2100 - val_loss: -150.8122\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2668 - loss: -141.5282 - val_accuracy: 0.2100 - val_loss: -152.4479\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2500 - loss: -145.1636 - val_accuracy: 0.2100 - val_loss: -154.0919\n",
            "Training on chunk 18/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2103 - loss: -149.5729 - val_accuracy: 0.2600 - val_loss: -135.5559\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2456 - loss: -143.9884 - val_accuracy: 0.2600 - val_loss: -136.9429\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2461 - loss: -145.1226 - val_accuracy: 0.2600 - val_loss: -138.3680\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.2228 - loss: -152.1652 - val_accuracy: 0.2600 - val_loss: -139.7879\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.2510 - loss: -143.8178 - val_accuracy: 0.2600 - val_loss: -141.1748\n",
            "Training on chunk 19/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2381 - loss: -150.6868 - val_accuracy: 0.2850 - val_loss: -144.1057\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2280 - loss: -156.4238 - val_accuracy: 0.2850 - val_loss: -145.5361\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2310 - loss: -155.3795 - val_accuracy: 0.2850 - val_loss: -146.9464\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - accuracy: 0.2256 - loss: -159.2492 - val_accuracy: 0.2850 - val_loss: -148.3754\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.2373 - loss: -153.1887 - val_accuracy: 0.2850 - val_loss: -149.7798\n",
            "Training on chunk 20/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2395 - loss: -164.6509 - val_accuracy: 0.2450 - val_loss: -161.8672\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.2223 - loss: -176.5841 - val_accuracy: 0.2450 - val_loss: -163.4810\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.2166 - loss: -172.4280 - val_accuracy: 0.2450 - val_loss: -165.0754\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 136ms/step - accuracy: 0.2217 - loss: -172.9098 - val_accuracy: 0.2450 - val_loss: -166.6825\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.2273 - loss: -177.3943 - val_accuracy: 0.2450 - val_loss: -168.3005\n",
            "Training on chunk 21/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2549 - loss: -164.0686 - val_accuracy: 0.2450 - val_loss: -170.9418\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2439 - loss: -168.0807 - val_accuracy: 0.2450 - val_loss: -172.4709\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 92ms/step - accuracy: 0.2505 - loss: -170.9698 - val_accuracy: 0.2450 - val_loss: -173.9920\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.2483 - loss: -172.6991 - val_accuracy: 0.2450 - val_loss: -175.5201\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.2613 - loss: -171.5284 - val_accuracy: 0.2450 - val_loss: -177.0365\n",
            "Training on chunk 22/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2345 - loss: -174.8868 - val_accuracy: 0.2100 - val_loss: -188.4681\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.2301 - loss: -176.9515 - val_accuracy: 0.2100 - val_loss: -190.0669\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.2323 - loss: -177.9555 - val_accuracy: 0.2100 - val_loss: -191.6753\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.2256 - loss: -182.0603 - val_accuracy: 0.2100 - val_loss: -193.2792\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.2316 - loss: -183.6024 - val_accuracy: 0.2100 - val_loss: -194.8918\n",
            "Training on chunk 23/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2770 - loss: -174.9336 - val_accuracy: 0.2350 - val_loss: -184.3140\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.2983 - loss: -170.9030 - val_accuracy: 0.2350 - val_loss: -185.7367\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2666 - loss: -178.2261 - val_accuracy: 0.2350 - val_loss: -187.1829\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - accuracy: 0.2847 - loss: -178.4541 - val_accuracy: 0.2350 - val_loss: -188.5906\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.2898 - loss: -178.1659 - val_accuracy: 0.2350 - val_loss: -190.0303\n",
            "Training on chunk 24/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2302 - loss: -195.7815 - val_accuracy: 0.1850 - val_loss: -213.5864\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.2199 - loss: -198.1037 - val_accuracy: 0.1850 - val_loss: -215.3191\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2211 - loss: -197.1075 - val_accuracy: 0.1850 - val_loss: -217.0574\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2479 - loss: -194.6386 - val_accuracy: 0.1850 - val_loss: -218.7603\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.2247 - loss: -205.2106 - val_accuracy: 0.1850 - val_loss: -220.5193\n",
            "Training on chunk 25/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.2784 - loss: -182.5416 - val_accuracy: 0.2300 - val_loss: -210.3427\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.2344 - loss: -186.0674 - val_accuracy: 0.2300 - val_loss: -211.8746\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2492 - loss: -183.7951 - val_accuracy: 0.2300 - val_loss: -213.3939\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.2289 - loss: -189.3598 - val_accuracy: 0.2300 - val_loss: -214.9187\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.2357 - loss: -195.7132 - val_accuracy: 0.2300 - val_loss: -216.4566\n",
            "Training on chunk 26/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2434 - loss: -205.3199 - val_accuracy: 0.2900 - val_loss: -193.5817\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.2607 - loss: -204.2266 - val_accuracy: 0.2900 - val_loss: -194.9868\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2585 - loss: -209.2708 - val_accuracy: 0.2900 - val_loss: -196.4069\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 117ms/step - accuracy: 0.2892 - loss: -196.7053 - val_accuracy: 0.2900 - val_loss: -197.8037\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.2600 - loss: -206.1771 - val_accuracy: 0.2900 - val_loss: -199.2119\n",
            "Training on chunk 27/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2742 - loss: -210.4905 - val_accuracy: 0.2300 - val_loss: -218.9097\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2308 - loss: -222.4319 - val_accuracy: 0.2300 - val_loss: -220.4575\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.2472 - loss: -216.1457 - val_accuracy: 0.2300 - val_loss: -221.9506\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.2594 - loss: -214.3353 - val_accuracy: 0.2300 - val_loss: -223.4509\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.2893 - loss: -206.1396 - val_accuracy: 0.2300 - val_loss: -224.9702\n",
            "Training on chunk 28/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2755 - loss: -207.3226 - val_accuracy: 0.2500 - val_loss: -217.7278\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.2655 - loss: -209.7964 - val_accuracy: 0.2500 - val_loss: -219.1487\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2779 - loss: -205.6638 - val_accuracy: 0.2500 - val_loss: -220.5575\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.2721 - loss: -212.9776 - val_accuracy: 0.2500 - val_loss: -221.9823\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.2680 - loss: -218.0089 - val_accuracy: 0.2500 - val_loss: -223.4370\n",
            "Training on chunk 29/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2694 - loss: -216.3576 - val_accuracy: 0.2400 - val_loss: -224.0844\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.3146 - loss: -204.1376 - val_accuracy: 0.2400 - val_loss: -225.4301\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.2861 - loss: -217.5620 - val_accuracy: 0.2400 - val_loss: -226.8303\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.2595 - loss: -216.9568 - val_accuracy: 0.2400 - val_loss: -228.2029\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.2954 - loss: -215.3260 - val_accuracy: 0.2400 - val_loss: -229.5764\n",
            "Training on chunk 30/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.2879 - loss: -217.4952 - val_accuracy: 0.2200 - val_loss: -237.9904\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.2803 - loss: -231.5657 - val_accuracy: 0.2200 - val_loss: -239.5364\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2930 - loss: -226.2381 - val_accuracy: 0.2200 - val_loss: -241.0410\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2687 - loss: -237.6362 - val_accuracy: 0.2200 - val_loss: -242.5831\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.2774 - loss: -233.1904 - val_accuracy: 0.2200 - val_loss: -244.0978\n",
            "Training on chunk 31/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.2332 - loss: -245.2477 - val_accuracy: 0.2750 - val_loss: -248.0424\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.2410 - loss: -245.0138 - val_accuracy: 0.2750 - val_loss: -249.5707\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2338 - loss: -248.9340 - val_accuracy: 0.2750 - val_loss: -251.1304\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.2429 - loss: -249.8815 - val_accuracy: 0.2750 - val_loss: -252.6762\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.2445 - loss: -241.2588 - val_accuracy: 0.2750 - val_loss: -254.2042\n",
            "Training on chunk 32/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2648 - loss: -240.9263 - val_accuracy: 0.2800 - val_loss: -254.9019\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.2786 - loss: -240.5475 - val_accuracy: 0.2800 - val_loss: -256.3754\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2699 - loss: -238.7832 - val_accuracy: 0.2800 - val_loss: -257.8526\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.2843 - loss: -238.0274 - val_accuracy: 0.2800 - val_loss: -259.3589\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.2606 - loss: -242.5142 - val_accuracy: 0.2800 - val_loss: -260.8553\n",
            "Training on chunk 33/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2354 - loss: -264.8818 - val_accuracy: 0.2100 - val_loss: -261.5714\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.2442 - loss: -259.6248 - val_accuracy: 0.2100 - val_loss: -263.1524\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.2384 - loss: -259.4040 - val_accuracy: 0.2100 - val_loss: -264.7305\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2278 - loss: -266.8700 - val_accuracy: 0.2100 - val_loss: -266.3239\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.2311 - loss: -265.8512 - val_accuracy: 0.2100 - val_loss: -267.8984\n",
            "Training on chunk 34/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2713 - loss: -246.2591 - val_accuracy: 0.2450 - val_loss: -270.2818\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.2327 - loss: -261.6475 - val_accuracy: 0.2450 - val_loss: -271.7600\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.2497 - loss: -255.2392 - val_accuracy: 0.2450 - val_loss: -273.2146\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2720 - loss: -245.1552 - val_accuracy: 0.2450 - val_loss: -274.6713\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.2653 - loss: -254.2971 - val_accuracy: 0.2450 - val_loss: -276.1604\n",
            "Training on chunk 35/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 130ms/step - accuracy: 0.2533 - loss: -271.1307 - val_accuracy: 0.2750 - val_loss: -260.5952\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.2507 - loss: -274.8434 - val_accuracy: 0.2750 - val_loss: -262.0299\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.2558 - loss: -273.7596 - val_accuracy: 0.2750 - val_loss: -263.4452\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2574 - loss: -272.8101 - val_accuracy: 0.2750 - val_loss: -264.8781\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 90ms/step - accuracy: 0.2769 - loss: -273.2137 - val_accuracy: 0.2750 - val_loss: -266.3106\n",
            "Training on chunk 36/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.2676 - loss: -274.0180 - val_accuracy: 0.1900 - val_loss: -288.0558\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2446 - loss: -265.6081 - val_accuracy: 0.1900 - val_loss: -289.5809\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.2515 - loss: -276.6284 - val_accuracy: 0.1900 - val_loss: -291.1395\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2392 - loss: -280.7014 - val_accuracy: 0.1900 - val_loss: -292.6850\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2487 - loss: -275.3775 - val_accuracy: 0.1900 - val_loss: -294.2267\n",
            "Training on chunk 37/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.2450 - loss: -283.6625 - val_accuracy: 0.3000 - val_loss: -262.6070\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.2400 - loss: -285.7412 - val_accuracy: 0.3000 - val_loss: -263.9983\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.2386 - loss: -285.8083 - val_accuracy: 0.3000 - val_loss: -265.3840\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.2609 - loss: -280.4323 - val_accuracy: 0.3000 - val_loss: -266.7604\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2686 - loss: -291.7027 - val_accuracy: 0.3000 - val_loss: -268.1490\n",
            "Training on chunk 38/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 94ms/step - accuracy: 0.2237 - loss: -303.1641 - val_accuracy: 0.2500 - val_loss: -283.1976\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2204 - loss: -302.1192 - val_accuracy: 0.2500 - val_loss: -284.7302\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2251 - loss: -299.4270 - val_accuracy: 0.2500 - val_loss: -286.2316\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2112 - loss: -312.5919 - val_accuracy: 0.2500 - val_loss: -287.7539\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2090 - loss: -318.0745 - val_accuracy: 0.2500 - val_loss: -289.2741\n",
            "Training on chunk 39/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2581 - loss: -305.3323 - val_accuracy: 0.2500 - val_loss: -313.7296\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2574 - loss: -299.5605 - val_accuracy: 0.2500 - val_loss: -315.2980\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.2549 - loss: -303.9555 - val_accuracy: 0.2500 - val_loss: -316.8913\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.2520 - loss: -306.3808 - val_accuracy: 0.2500 - val_loss: -318.4630\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2431 - loss: -304.5757 - val_accuracy: 0.2500 - val_loss: -320.0477\n",
            "Training on chunk 40/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2332 - loss: -307.1020 - val_accuracy: 0.2550 - val_loss: -307.2681\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2299 - loss: -319.5557 - val_accuracy: 0.2550 - val_loss: -308.7604\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.2461 - loss: -305.6222 - val_accuracy: 0.2550 - val_loss: -310.2355\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2322 - loss: -315.9929 - val_accuracy: 0.2550 - val_loss: -311.7170\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.2355 - loss: -312.7917 - val_accuracy: 0.2550 - val_loss: -313.1888\n",
            "Training on chunk 41/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2447 - loss: -313.8886 - val_accuracy: 0.2300 - val_loss: -315.7118\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2637 - loss: -311.7132 - val_accuracy: 0.2300 - val_loss: -317.2101\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - accuracy: 0.2337 - loss: -317.2208 - val_accuracy: 0.2300 - val_loss: -318.6812\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.2591 - loss: -306.8969 - val_accuracy: 0.2300 - val_loss: -320.1644\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2315 - loss: -328.1506 - val_accuracy: 0.2300 - val_loss: -321.6573\n",
            "Training on chunk 42/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2684 - loss: -322.0953 - val_accuracy: 0.2900 - val_loss: -302.7394\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2605 - loss: -329.9275 - val_accuracy: 0.2900 - val_loss: -304.1666\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.2726 - loss: -320.2489 - val_accuracy: 0.2900 - val_loss: -305.5624\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.2604 - loss: -325.8713 - val_accuracy: 0.2900 - val_loss: -306.9771\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.2574 - loss: -333.4542 - val_accuracy: 0.2900 - val_loss: -308.3979\n",
            "Training on chunk 43/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2813 - loss: -323.2876 - val_accuracy: 0.2850 - val_loss: -326.2857\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2397 - loss: -337.1573 - val_accuracy: 0.2850 - val_loss: -327.7845\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2649 - loss: -330.4418 - val_accuracy: 0.2850 - val_loss: -329.2694\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - accuracy: 0.2433 - loss: -345.3054 - val_accuracy: 0.2850 - val_loss: -330.7714\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.2447 - loss: -336.3068 - val_accuracy: 0.2850 - val_loss: -332.2507\n",
            "Training on chunk 44/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2322 - loss: -347.5203 - val_accuracy: 0.2950 - val_loss: -345.0004\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2271 - loss: -349.1375 - val_accuracy: 0.2950 - val_loss: -346.5478\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.2461 - loss: -344.8500 - val_accuracy: 0.2950 - val_loss: -348.0957\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.2385 - loss: -344.4509 - val_accuracy: 0.2950 - val_loss: -349.6501\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.2214 - loss: -355.4234 - val_accuracy: 0.2950 - val_loss: -351.1950\n",
            "Training on chunk 45/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2433 - loss: -344.9777 - val_accuracy: 0.2500 - val_loss: -337.7849\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2579 - loss: -345.0498 - val_accuracy: 0.2500 - val_loss: -339.2505\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2391 - loss: -361.4529 - val_accuracy: 0.2500 - val_loss: -340.7361\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2430 - loss: -354.9421 - val_accuracy: 0.2500 - val_loss: -342.2086\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - accuracy: 0.2528 - loss: -352.9850 - val_accuracy: 0.2500 - val_loss: -343.6526\n",
            "Training on chunk 46/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.2361 - loss: -342.4593 - val_accuracy: 0.2900 - val_loss: -350.9615\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2408 - loss: -349.1454 - val_accuracy: 0.2900 - val_loss: -352.4126\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2489 - loss: -341.4110 - val_accuracy: 0.2900 - val_loss: -353.8356\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2541 - loss: -345.3938 - val_accuracy: 0.2900 - val_loss: -355.2856\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2170 - loss: -367.5443 - val_accuracy: 0.2900 - val_loss: -356.7374\n",
            "Training on chunk 47/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2449 - loss: -360.1431 - val_accuracy: 0.2350 - val_loss: -374.9575\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.2537 - loss: -357.9475 - val_accuracy: 0.2350 - val_loss: -376.5160\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.2565 - loss: -357.8011 - val_accuracy: 0.2350 - val_loss: -378.0747\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2415 - loss: -369.0077 - val_accuracy: 0.2350 - val_loss: -379.6311\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.2409 - loss: -363.8514 - val_accuracy: 0.2350 - val_loss: -381.1888\n",
            "Training on chunk 48/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.2258 - loss: -386.7206 - val_accuracy: 0.3100 - val_loss: -317.9758\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2474 - loss: -363.4337 - val_accuracy: 0.3100 - val_loss: -319.2867\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2536 - loss: -370.5177 - val_accuracy: 0.3100 - val_loss: -320.6255\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.2419 - loss: -383.8243 - val_accuracy: 0.3100 - val_loss: -321.9712\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2457 - loss: -383.8988 - val_accuracy: 0.3100 - val_loss: -323.3120\n",
            "Training on chunk 49/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.2788 - loss: -349.5319 - val_accuracy: 0.1900 - val_loss: -429.4502\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.2690 - loss: -355.6199 - val_accuracy: 0.1900 - val_loss: -431.1239\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2769 - loss: -355.9326 - val_accuracy: 0.1900 - val_loss: -432.7742\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2685 - loss: -365.0718 - val_accuracy: 0.1900 - val_loss: -434.4331\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2676 - loss: -360.9948 - val_accuracy: 0.1900 - val_loss: -436.0858\n",
            "Training on chunk 50/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.2572 - loss: -375.7820 - val_accuracy: 0.2300 - val_loss: -400.8694\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.2573 - loss: -373.2706 - val_accuracy: 0.2300 - val_loss: -402.4226\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.2406 - loss: -382.0954 - val_accuracy: 0.2300 - val_loss: -403.9821\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2277 - loss: -391.2990 - val_accuracy: 0.2300 - val_loss: -405.5413\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2484 - loss: -380.8747 - val_accuracy: 0.2300 - val_loss: -407.0638\n",
            "Training on chunk 51/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.2541 - loss: -382.4518 - val_accuracy: 0.2700 - val_loss: -387.8693\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 118ms/step - accuracy: 0.2506 - loss: -395.3613 - val_accuracy: 0.2700 - val_loss: -389.3480\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2586 - loss: -384.2165 - val_accuracy: 0.2700 - val_loss: -390.8286\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2687 - loss: -375.3618 - val_accuracy: 0.2700 - val_loss: -392.2772\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.2505 - loss: -399.7490 - val_accuracy: 0.2700 - val_loss: -393.7572\n",
            "Training on chunk 52/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2426 - loss: -392.4667 - val_accuracy: 0.2600 - val_loss: -376.7356\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.2546 - loss: -388.0076 - val_accuracy: 0.2600 - val_loss: -378.1596\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.2363 - loss: -400.3924 - val_accuracy: 0.2600 - val_loss: -379.5844\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.2229 - loss: -404.7052 - val_accuracy: 0.2600 - val_loss: -381.0094\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2526 - loss: -398.5870 - val_accuracy: 0.2600 - val_loss: -382.4240\n",
            "Training on chunk 53/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2431 - loss: -397.0994 - val_accuracy: 0.2450 - val_loss: -406.7383\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.2757 - loss: -385.9073 - val_accuracy: 0.2450 - val_loss: -408.2317\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.2271 - loss: -423.9326 - val_accuracy: 0.2450 - val_loss: -409.7533\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.2385 - loss: -418.4331 - val_accuracy: 0.2450 - val_loss: -411.2457\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.2274 - loss: -429.8794 - val_accuracy: 0.2450 - val_loss: -412.7537\n",
            "Training on chunk 54/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2848 - loss: -402.0137 - val_accuracy: 0.2400 - val_loss: -415.6093\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2410 - loss: -426.6746 - val_accuracy: 0.2400 - val_loss: -417.1511\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2625 - loss: -413.9670 - val_accuracy: 0.2400 - val_loss: -418.6720\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.2653 - loss: -404.6653 - val_accuracy: 0.2400 - val_loss: -420.1913\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2665 - loss: -417.9678 - val_accuracy: 0.2400 - val_loss: -421.7362\n",
            "Training on chunk 55/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2829 - loss: -399.6427 - val_accuracy: 0.2400 - val_loss: -431.5939\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2850 - loss: -401.3251 - val_accuracy: 0.2400 - val_loss: -433.0737\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step - accuracy: 0.2836 - loss: -410.7195 - val_accuracy: 0.2400 - val_loss: -434.5953\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.2659 - loss: -426.7094 - val_accuracy: 0.2400 - val_loss: -436.0801\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2802 - loss: -411.8643 - val_accuracy: 0.2400 - val_loss: -437.5615\n",
            "Training on chunk 56/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2791 - loss: -419.0267 - val_accuracy: 0.2700 - val_loss: -410.6537\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2663 - loss: -413.0632 - val_accuracy: 0.2700 - val_loss: -412.0625\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 87ms/step - accuracy: 0.2407 - loss: -429.7981 - val_accuracy: 0.2700 - val_loss: -413.4865\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.2541 - loss: -422.1437 - val_accuracy: 0.2700 - val_loss: -414.9174\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.2650 - loss: -427.9981 - val_accuracy: 0.2700 - val_loss: -416.3290\n",
            "Training on chunk 57/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.2534 - loss: -435.6278 - val_accuracy: 0.2900 - val_loss: -429.3212\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2834 - loss: -419.3926 - val_accuracy: 0.2900 - val_loss: -430.7718\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.2626 - loss: -432.3012 - val_accuracy: 0.2900 - val_loss: -432.2350\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.2782 - loss: -434.1101 - val_accuracy: 0.2900 - val_loss: -433.7137\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.3039 - loss: -417.8807 - val_accuracy: 0.2900 - val_loss: -435.1632\n",
            "Training on chunk 58/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2357 - loss: -448.4133 - val_accuracy: 0.2500 - val_loss: -444.0011\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2455 - loss: -442.2232 - val_accuracy: 0.2500 - val_loss: -445.5272\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2484 - loss: -451.7239 - val_accuracy: 0.2500 - val_loss: -447.0570\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2552 - loss: -444.4069 - val_accuracy: 0.2500 - val_loss: -448.5752\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - accuracy: 0.2412 - loss: -460.2943 - val_accuracy: 0.2500 - val_loss: -450.1180\n",
            "Training on chunk 59/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2337 - loss: -435.4201 - val_accuracy: 0.2650 - val_loss: -454.5894\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2472 - loss: -434.8481 - val_accuracy: 0.2650 - val_loss: -456.0767\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2503 - loss: -426.5308 - val_accuracy: 0.2650 - val_loss: -457.5551\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2435 - loss: -442.0294 - val_accuracy: 0.2650 - val_loss: -459.0417\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.2307 - loss: -443.7426 - val_accuracy: 0.2650 - val_loss: -460.5387\n",
            "Training on chunk 60/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2370 - loss: -449.3647 - val_accuracy: 0.2300 - val_loss: -474.1991\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2466 - loss: -455.2445 - val_accuracy: 0.2300 - val_loss: -475.7817\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2189 - loss: -493.2363 - val_accuracy: 0.2300 - val_loss: -477.3644\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2482 - loss: -473.4669 - val_accuracy: 0.2300 - val_loss: -478.9336\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.2383 - loss: -473.3913 - val_accuracy: 0.2300 - val_loss: -480.4990\n",
            "Training on chunk 61/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2475 - loss: -452.7115 - val_accuracy: 0.2750 - val_loss: -437.2308\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.2585 - loss: -449.0009 - val_accuracy: 0.2750 - val_loss: -438.6048\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2520 - loss: -446.3602 - val_accuracy: 0.2750 - val_loss: -439.9781\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2605 - loss: -445.1309 - val_accuracy: 0.2750 - val_loss: -441.3566\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - accuracy: 0.2370 - loss: -463.1756 - val_accuracy: 0.2750 - val_loss: -442.7400\n",
            "Training on chunk 62/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2211 - loss: -482.4938 - val_accuracy: 0.2250 - val_loss: -464.5470\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2442 - loss: -470.7543 - val_accuracy: 0.2250 - val_loss: -466.0325\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2669 - loss: -446.5896 - val_accuracy: 0.2250 - val_loss: -467.5028\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2272 - loss: -492.4375 - val_accuracy: 0.2250 - val_loss: -469.0080\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - accuracy: 0.2482 - loss: -471.4839 - val_accuracy: 0.2250 - val_loss: -470.4671\n",
            "Training on chunk 63/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2453 - loss: -469.5732 - val_accuracy: 0.2900 - val_loss: -424.1225\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2711 - loss: -457.2007 - val_accuracy: 0.2900 - val_loss: -425.4150\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.2455 - loss: -488.0098 - val_accuracy: 0.2900 - val_loss: -426.7394\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2614 - loss: -465.6144 - val_accuracy: 0.2900 - val_loss: -428.0478\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.2427 - loss: -491.1241 - val_accuracy: 0.2900 - val_loss: -429.3815\n",
            "Training on chunk 64/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2681 - loss: -476.5028 - val_accuracy: 0.2550 - val_loss: -513.2534\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2367 - loss: -492.3505 - val_accuracy: 0.2550 - val_loss: -514.8296\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.2442 - loss: -487.6068 - val_accuracy: 0.2550 - val_loss: -516.3906\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.2489 - loss: -487.8097 - val_accuracy: 0.2550 - val_loss: -517.9579\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2400 - loss: -494.2160 - val_accuracy: 0.2550 - val_loss: -519.5070\n",
            "Training on chunk 65/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.2535 - loss: -473.8321 - val_accuracy: 0.2350 - val_loss: -471.7385\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.2294 - loss: -493.8555 - val_accuracy: 0.2350 - val_loss: -473.1544\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.2340 - loss: -485.1386 - val_accuracy: 0.2350 - val_loss: -474.5724\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.2454 - loss: -487.0195 - val_accuracy: 0.2350 - val_loss: -475.9766\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.2392 - loss: -482.7785 - val_accuracy: 0.2350 - val_loss: -477.3737\n",
            "Training on chunk 66/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 152ms/step - accuracy: 0.2888 - loss: -478.2816 - val_accuracy: 0.2800 - val_loss: -465.4340\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.2629 - loss: -496.1820 - val_accuracy: 0.2800 - val_loss: -466.8108\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.2666 - loss: -493.6704 - val_accuracy: 0.2800 - val_loss: -468.1734\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2786 - loss: -490.9418 - val_accuracy: 0.2800 - val_loss: -469.5323\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.2674 - loss: -509.8909 - val_accuracy: 0.2800 - val_loss: -470.9090\n",
            "Training on chunk 67/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2773 - loss: -498.4092 - val_accuracy: 0.2600 - val_loss: -524.7438\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2837 - loss: -493.5595 - val_accuracy: 0.2600 - val_loss: -526.2707\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2480 - loss: -524.4246 - val_accuracy: 0.2600 - val_loss: -527.8445\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.2630 - loss: -510.5104 - val_accuracy: 0.2600 - val_loss: -529.3779\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 123ms/step - accuracy: 0.2642 - loss: -521.9474 - val_accuracy: 0.2600 - val_loss: -530.9249\n",
            "Training on chunk 68/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2657 - loss: -502.1259 - val_accuracy: 0.2350 - val_loss: -513.5466\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.2459 - loss: -503.2907 - val_accuracy: 0.2350 - val_loss: -515.0256\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.2773 - loss: -492.4048 - val_accuracy: 0.2350 - val_loss: -516.4839\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 107ms/step - accuracy: 0.2590 - loss: -509.0945 - val_accuracy: 0.2350 - val_loss: -517.9649\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2663 - loss: -521.4887 - val_accuracy: 0.2350 - val_loss: -519.4417\n",
            "Training on chunk 69/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.1859 - loss: -560.6758 - val_accuracy: 0.2600 - val_loss: -500.0773\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2135 - loss: -557.7460 - val_accuracy: 0.2600 - val_loss: -501.5647\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2080 - loss: -560.6968 - val_accuracy: 0.2600 - val_loss: -503.0458\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.2450 - loss: -521.9622 - val_accuracy: 0.2600 - val_loss: -504.5197\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.2194 - loss: -543.1526 - val_accuracy: 0.2600 - val_loss: -506.0219\n",
            "Training on chunk 70/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2665 - loss: -529.6572 - val_accuracy: 0.2600 - val_loss: -526.9252\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.2633 - loss: -526.7047 - val_accuracy: 0.2600 - val_loss: -528.3982\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2638 - loss: -534.6697 - val_accuracy: 0.2600 - val_loss: -529.9057\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - accuracy: 0.2443 - loss: -530.8629 - val_accuracy: 0.2600 - val_loss: -531.3831\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.2438 - loss: -553.5850 - val_accuracy: 0.2600 - val_loss: -532.8799\n",
            "Training on chunk 71/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2422 - loss: -539.2598 - val_accuracy: 0.2650 - val_loss: -521.8281\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.2580 - loss: -539.0199 - val_accuracy: 0.2650 - val_loss: -523.2925\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.2772 - loss: -525.8699 - val_accuracy: 0.2650 - val_loss: -524.7700\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 104ms/step - accuracy: 0.2279 - loss: -562.6088 - val_accuracy: 0.2650 - val_loss: -526.2773\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.2353 - loss: -545.9188 - val_accuracy: 0.2650 - val_loss: -527.7443\n",
            "Training on chunk 72/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 109ms/step - accuracy: 0.2572 - loss: -550.8329 - val_accuracy: 0.2600 - val_loss: -509.1903\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.2521 - loss: -541.8597 - val_accuracy: 0.2600 - val_loss: -510.5858\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2601 - loss: -555.1385 - val_accuracy: 0.2600 - val_loss: -511.9925\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.2458 - loss: -575.0616 - val_accuracy: 0.2600 - val_loss: -513.4044\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.2910 - loss: -544.2700 - val_accuracy: 0.2600 - val_loss: -514.7828\n",
            "Training on chunk 73/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.2290 - loss: -556.9343 - val_accuracy: 0.2600 - val_loss: -521.7244\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.2110 - loss: -556.3001 - val_accuracy: 0.2600 - val_loss: -523.1510\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.2171 - loss: -586.2951 - val_accuracy: 0.2600 - val_loss: -524.5984\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 91ms/step - accuracy: 0.2533 - loss: -553.8274 - val_accuracy: 0.2600 - val_loss: -526.0170\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.2291 - loss: -584.9724 - val_accuracy: 0.2600 - val_loss: -527.4536\n",
            "Training on chunk 74/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.3032 - loss: -516.3268 - val_accuracy: 0.2500 - val_loss: -568.0717\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.2787 - loss: -539.8369 - val_accuracy: 0.2500 - val_loss: -569.5510\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.2842 - loss: -524.6213 - val_accuracy: 0.2500 - val_loss: -571.0060\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - accuracy: 0.2611 - loss: -574.5984 - val_accuracy: 0.2500 - val_loss: -572.4945\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.2784 - loss: -544.5364 - val_accuracy: 0.2500 - val_loss: -573.9444\n",
            "Training on chunk 75/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.2767 - loss: -540.8813 - val_accuracy: 0.2100 - val_loss: -590.5291\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2720 - loss: -544.9376 - val_accuracy: 0.2100 - val_loss: -592.0034\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2468 - loss: -561.0348 - val_accuracy: 0.2100 - val_loss: -593.4858\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.2769 - loss: -543.0042 - val_accuracy: 0.2100 - val_loss: -594.9609\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 129ms/step - accuracy: 0.2870 - loss: -548.5826 - val_accuracy: 0.2100 - val_loss: -596.4196\n",
            "Training on chunk 76/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2691 - loss: -578.6543 - val_accuracy: 0.2400 - val_loss: -561.5508\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2693 - loss: -567.1476 - val_accuracy: 0.2400 - val_loss: -563.0009\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2354 - loss: -605.4178 - val_accuracy: 0.2400 - val_loss: -564.4860\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2637 - loss: -578.1099 - val_accuracy: 0.2400 - val_loss: -565.9370\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 99ms/step - accuracy: 0.2686 - loss: -573.6147 - val_accuracy: 0.2400 - val_loss: -567.4077\n",
            "Training on chunk 77/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 134ms/step - accuracy: 0.2482 - loss: -579.5478 - val_accuracy: 0.2600 - val_loss: -531.9861\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.2542 - loss: -588.6553 - val_accuracy: 0.2600 - val_loss: -533.3679\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2535 - loss: -598.0534 - val_accuracy: 0.2600 - val_loss: -534.7559\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2368 - loss: -599.1463 - val_accuracy: 0.2600 - val_loss: -536.1417\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 102ms/step - accuracy: 0.2545 - loss: -597.6186 - val_accuracy: 0.2600 - val_loss: -537.5121\n",
            "Training on chunk 78/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2294 - loss: -596.4252 - val_accuracy: 0.2350 - val_loss: -615.5877\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2327 - loss: -606.7260 - val_accuracy: 0.2350 - val_loss: -617.1605\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2242 - loss: -600.3406 - val_accuracy: 0.2350 - val_loss: -618.7329\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.2402 - loss: -591.0488 - val_accuracy: 0.2350 - val_loss: -620.2810\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2670 - loss: -554.0911 - val_accuracy: 0.2350 - val_loss: -621.8275\n",
            "Training on chunk 79/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.2865 - loss: -553.5056 - val_accuracy: 0.2000 - val_loss: -675.1415\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.2946 - loss: -551.7114 - val_accuracy: 0.2000 - val_loss: -676.7786\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2540 - loss: -595.2806 - val_accuracy: 0.2000 - val_loss: -678.4313\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2709 - loss: -570.9659 - val_accuracy: 0.2000 - val_loss: -680.0574\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2736 - loss: -564.0862 - val_accuracy: 0.2000 - val_loss: -681.6792\n",
            "Training on chunk 80/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.2861 - loss: -591.7173 - val_accuracy: 0.2700 - val_loss: -568.4601\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 119ms/step - accuracy: 0.2506 - loss: -625.6241 - val_accuracy: 0.2700 - val_loss: -569.8837\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.2748 - loss: -585.2916 - val_accuracy: 0.2700 - val_loss: -571.2815\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.2556 - loss: -620.9002 - val_accuracy: 0.2700 - val_loss: -572.7040\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2727 - loss: -589.0387 - val_accuracy: 0.2700 - val_loss: -574.1039\n",
            "Training on chunk 81/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 108ms/step - accuracy: 0.2514 - loss: -607.8845 - val_accuracy: 0.3050 - val_loss: -559.2244\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 120ms/step - accuracy: 0.2084 - loss: -660.1279 - val_accuracy: 0.3050 - val_loss: -560.6517\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2104 - loss: -659.2138 - val_accuracy: 0.3050 - val_loss: -562.0565\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.2299 - loss: -652.4909 - val_accuracy: 0.3050 - val_loss: -563.4615\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2347 - loss: -634.4927 - val_accuracy: 0.3050 - val_loss: -564.8602\n",
            "Training on chunk 82/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2431 - loss: -621.8105 - val_accuracy: 0.2950 - val_loss: -601.3745\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.2475 - loss: -628.1636 - val_accuracy: 0.2950 - val_loss: -602.8239\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.2251 - loss: -649.7563 - val_accuracy: 0.2950 - val_loss: -604.2901\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2597 - loss: -603.7220 - val_accuracy: 0.2950 - val_loss: -605.7079\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2307 - loss: -634.3287 - val_accuracy: 0.2950 - val_loss: -607.1721\n",
            "Training on chunk 83/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.2720 - loss: -621.7911 - val_accuracy: 0.2800 - val_loss: -596.0598\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.2737 - loss: -622.2618 - val_accuracy: 0.2800 - val_loss: -597.4766\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.2622 - loss: -641.2327 - val_accuracy: 0.2800 - val_loss: -598.8922\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2864 - loss: -632.7435 - val_accuracy: 0.2800 - val_loss: -600.3102\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.2859 - loss: -605.3808 - val_accuracy: 0.2800 - val_loss: -601.7215\n",
            "Training on chunk 84/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2696 - loss: -630.2241 - val_accuracy: 0.2150 - val_loss: -704.7031\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.2883 - loss: -602.0923 - val_accuracy: 0.2150 - val_loss: -706.3248\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.2640 - loss: -643.0173 - val_accuracy: 0.2150 - val_loss: -707.9829\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2717 - loss: -631.1061 - val_accuracy: 0.2150 - val_loss: -709.6264\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.2707 - loss: -618.7237 - val_accuracy: 0.2150 - val_loss: -711.2450\n",
            "Training on chunk 85/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2321 - loss: -639.9609 - val_accuracy: 0.2300 - val_loss: -665.8015\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.2273 - loss: -656.0599 - val_accuracy: 0.2300 - val_loss: -667.3608\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2342 - loss: -648.6234 - val_accuracy: 0.2300 - val_loss: -668.9076\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - accuracy: 0.2455 - loss: -645.2833 - val_accuracy: 0.2300 - val_loss: -670.4604\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.2182 - loss: -660.1205 - val_accuracy: 0.2300 - val_loss: -672.0296\n",
            "Training on chunk 86/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2402 - loss: -665.4695 - val_accuracy: 0.2700 - val_loss: -623.7639\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2656 - loss: -633.5149 - val_accuracy: 0.2700 - val_loss: -625.1867\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - accuracy: 0.2435 - loss: -654.7482 - val_accuracy: 0.2700 - val_loss: -626.6238\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.2353 - loss: -663.6974 - val_accuracy: 0.2700 - val_loss: -628.0598\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.2456 - loss: -649.1404 - val_accuracy: 0.2700 - val_loss: -629.5000\n",
            "Training on chunk 87/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2637 - loss: -638.0737 - val_accuracy: 0.2500 - val_loss: -659.3974\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.2452 - loss: -650.0887 - val_accuracy: 0.2500 - val_loss: -660.8635\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2425 - loss: -661.6950 - val_accuracy: 0.2500 - val_loss: -662.3182\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.2540 - loss: -659.5029 - val_accuracy: 0.2500 - val_loss: -663.7689\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.2508 - loss: -662.9557 - val_accuracy: 0.2500 - val_loss: -665.2415\n",
            "Training on chunk 88/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2567 - loss: -658.3019 - val_accuracy: 0.2550 - val_loss: -653.4235\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.2982 - loss: -629.8671 - val_accuracy: 0.2550 - val_loss: -654.8593\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.2493 - loss: -656.8773 - val_accuracy: 0.2550 - val_loss: -656.3228\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2573 - loss: -643.7643 - val_accuracy: 0.2550 - val_loss: -657.7659\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2498 - loss: -651.8713 - val_accuracy: 0.2550 - val_loss: -659.2177\n",
            "Training on chunk 89/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2557 - loss: -652.0049 - val_accuracy: 0.3200 - val_loss: -604.6780\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.2592 - loss: -660.0659 - val_accuracy: 0.3200 - val_loss: -606.0071\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.2199 - loss: -687.6390 - val_accuracy: 0.3200 - val_loss: -607.3455\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2509 - loss: -682.6160 - val_accuracy: 0.3200 - val_loss: -608.6656\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.2703 - loss: -652.2258 - val_accuracy: 0.3200 - val_loss: -609.9684\n",
            "Training on chunk 90/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2427 - loss: -690.9800 - val_accuracy: 0.2500 - val_loss: -681.5115\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.2508 - loss: -695.3364 - val_accuracy: 0.2500 - val_loss: -683.0093\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2634 - loss: -687.5970 - val_accuracy: 0.2500 - val_loss: -684.5179\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - accuracy: 0.2546 - loss: -702.7455 - val_accuracy: 0.2500 - val_loss: -686.0297\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 84ms/step - accuracy: 0.2751 - loss: -680.9306 - val_accuracy: 0.2500 - val_loss: -687.5198\n",
            "Training on chunk 91/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.2642 - loss: -673.3738 - val_accuracy: 0.2200 - val_loss: -670.7081\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 88ms/step - accuracy: 0.2558 - loss: -680.3499 - val_accuracy: 0.2200 - val_loss: -672.1353\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 125ms/step - accuracy: 0.2642 - loss: -679.2199 - val_accuracy: 0.2200 - val_loss: -673.5672\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.2607 - loss: -704.4537 - val_accuracy: 0.2200 - val_loss: -675.0197\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.2504 - loss: -682.2985 - val_accuracy: 0.2200 - val_loss: -676.4318\n",
            "Training on chunk 92/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2780 - loss: -672.5357 - val_accuracy: 0.2550 - val_loss: -698.6930\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 89ms/step - accuracy: 0.2468 - loss: -689.9640 - val_accuracy: 0.2550 - val_loss: -700.1531\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.2679 - loss: -658.6963 - val_accuracy: 0.2550 - val_loss: -701.5945\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.2890 - loss: -668.7276 - val_accuracy: 0.2550 - val_loss: -703.0695\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2444 - loss: -692.6306 - val_accuracy: 0.2550 - val_loss: -704.5383\n",
            "Training on chunk 93/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2341 - loss: -731.7325 - val_accuracy: 0.2100 - val_loss: -776.1933\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2618 - loss: -720.3632 - val_accuracy: 0.2100 - val_loss: -777.8964\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.2459 - loss: -737.5466 - val_accuracy: 0.2100 - val_loss: -779.5912\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 121ms/step - accuracy: 0.2615 - loss: -699.4962 - val_accuracy: 0.2100 - val_loss: -781.2852\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.2519 - loss: -729.3302 - val_accuracy: 0.2100 - val_loss: -782.9966\n",
            "Training on chunk 94/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step - accuracy: 0.2479 - loss: -715.4173 - val_accuracy: 0.2350 - val_loss: -690.1357\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2468 - loss: -731.5185 - val_accuracy: 0.2350 - val_loss: -691.5847\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.2424 - loss: -721.1882 - val_accuracy: 0.2350 - val_loss: -693.0331\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step - accuracy: 0.2583 - loss: -709.0385 - val_accuracy: 0.2350 - val_loss: -694.4680\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.2367 - loss: -717.8046 - val_accuracy: 0.2350 - val_loss: -695.9252\n",
            "Training on chunk 95/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.2540 - loss: -684.0117 - val_accuracy: 0.2050 - val_loss: -785.7163\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.2232 - loss: -711.1936 - val_accuracy: 0.2050 - val_loss: -787.3127\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 97ms/step - accuracy: 0.2449 - loss: -710.4174 - val_accuracy: 0.2050 - val_loss: -788.9115\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step - accuracy: 0.2305 - loss: -699.6409 - val_accuracy: 0.2050 - val_loss: -790.4958\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.2681 - loss: -689.8406 - val_accuracy: 0.2050 - val_loss: -792.0848\n",
            "Training on chunk 96/96\n",
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.2420 - loss: -718.1783 - val_accuracy: 0.2450 - val_loss: -757.5274\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - accuracy: 0.2292 - loss: -730.8756 - val_accuracy: 0.2450 - val_loss: -759.1026\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - accuracy: 0.2099 - loss: -747.0383 - val_accuracy: 0.2450 - val_loss: -760.6658\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 127ms/step - accuracy: 0.2541 - loss: -716.3663 - val_accuracy: 0.2450 - val_loss: -762.2302\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.2340 - loss: -720.4782 - val_accuracy: 0.2450 - val_loss: -763.7753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWfJXtFnaDog",
        "outputId": "7b1d952e-1d75-48da-e907-5f52033dbdfd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  fonts-urw-base35 libapache-pom-java libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3\n",
            "  libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1 libgs9 libgs9-common\n",
            "  libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0 libsynctex2\n",
            "  libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern pandoc-data poppler-data\n",
            "  preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0\n",
            "  rubygems-integration t1utils teckit tex-common tex-gyre texlive-base texlive-binaries\n",
            "  texlive-fonts-recommended texlive-latex-base texlive-latex-recommended texlive-pictures\n",
            "  texlive-plain-generic tipa xfonts-encodings xfonts-utils\n",
            "Suggested packages:\n",
            "  fonts-noto fonts-freefont-otf | fonts-freefont-ttf libavalon-framework-java\n",
            "  libcommons-logging-java-doc libexcalibur-logkit-java liblog4j1.2-java texlive-luatex\n",
            "  pandoc-citeproc context wkhtmltopdf librsvg2-bin groff ghc nodejs php python libjs-mathjax\n",
            "  libjs-katex citation-style-language-styles poppler-utils ghostscript fonts-japanese-mincho\n",
            "  | fonts-ipafont-mincho fonts-japanese-gothic | fonts-ipafont-gothic fonts-arphic-ukai\n",
            "  fonts-arphic-uming fonts-nanum ri ruby-dev bundler debhelper gv | postscript-viewer perl-tk xpdf\n",
            "  | pdf-viewer xzdec texlive-fonts-recommended-doc texlive-latex-base-doc python3-pygments\n",
            "  icc-profiles libfile-which-perl libspreadsheet-parseexcel-perl texlive-latex-extra-doc\n",
            "  texlive-latex-recommended-doc texlive-pstricks dot2tex prerex texlive-pictures-doc vprerex\n",
            "  default-jre-headless tipa-doc\n",
            "The following NEW packages will be installed:\n",
            "  dvisvgm fonts-droid-fallback fonts-lato fonts-lmodern fonts-noto-mono fonts-texgyre\n",
            "  fonts-urw-base35 libapache-pom-java libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3\n",
            "  libcommons-logging-java libcommons-parent-java libfontbox-java libfontenc1 libgs9 libgs9-common\n",
            "  libidn12 libijs-0.35 libjbig2dec0 libkpathsea6 libpdfbox-java libptexenc1 libruby3.0 libsynctex2\n",
            "  libteckit0 libtexlua53 libtexluajit2 libwoff1 libzzip-0-13 lmodern pandoc pandoc-data\n",
            "  poppler-data preview-latex-style rake ruby ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc\n",
            "  ruby3.0 rubygems-integration t1utils teckit tex-common tex-gyre texlive texlive-base\n",
            "  texlive-binaries texlive-fonts-recommended texlive-latex-base texlive-latex-extra\n",
            "  texlive-latex-recommended texlive-pictures texlive-plain-generic texlive-xetex tipa\n",
            "  xfonts-encodings xfonts-utils\n",
            "0 upgraded, 59 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 202 MB of archives.\n",
            "After this operation, 728 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-droid-fallback all 1:6.0.1r16-1.1build1 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 poppler-data all 0.4.11-1 [2,171 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-common all 6.17 [33.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-urw-base35 all 20200910-1 [6,367 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9-common all 9.55.0~dfsg1-0ubuntu5.9 [752 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libidn12 amd64 1.38-4ubuntu1 [60.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libijs-0.35 amd64 0.35-15build2 [16.5 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjbig2dec0 amd64 0.19-3build2 [64.7 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgs9 amd64 9.55.0~dfsg1-0ubuntu5.9 [5,033 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libkpathsea6 amd64 2021.20210626.59705-1ubuntu0.2 [60.4 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dvisvgm amd64 2.13.1-1 [1,221 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-lmodern all 2.004.5-6.1 [4,532 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-noto-mono all 20201225-1build1 [397 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fonts-texgyre all 20180621-3.1 [10.2 MB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libapache-pom-java all 18-1 [4,720 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [115 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm-extensions0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [25.1 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-parent-java all 43-1 [10.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcommons-logging-java all 1.2-2 [60.3 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libptexenc1 amd64 2021.20210626.59705-1ubuntu0.2 [39.1 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.7 [50.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-rubygems all 3.3.5-2 [228 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ruby-webrick all 1.7.0-3 [51.8 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.7 [5,113 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsynctex2 amd64 2021.20210626.59705-1ubuntu0.2 [55.6 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libteckit0 amd64 2.5.11+ds1-1 [421 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexlua53 amd64 2021.20210626.59705-1ubuntu0.2 [120 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libtexluajit2 amd64 2021.20210626.59705-1ubuntu0.2 [267 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libzzip-0-13 amd64 0.13.72+dfsg.1-1.1 [27.0 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lmodern all 2.004.5-6.1 [9,471 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc-data all 2.9.2.1-3ubuntu2 [81.8 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc amd64 2.9.2.1-3ubuntu2 [20.3 MB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 preview-latex-style all 12.2-1ubuntu1 [185 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 t1utils amd64 1.41-4build2 [61.3 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 teckit amd64 2.5.11+ds1-1 [699 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tex-gyre all 20180621-3.1 [6,209 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 texlive-binaries amd64 2021.20210626.59705-1ubuntu0.2 [9,860 kB]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-base all 2021.20220204-1 [21.0 MB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-fonts-recommended all 2021.20220204-1 [4,972 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-base all 2021.20220204-1 [1,128 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-recommended all 2021.20220204-1 [14.4 MB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive all 2021.20220204-1 [14.3 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfontbox-java all 1:1.8.16-2 [207 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libpdfbox-java all 1:1.8.16-2 [5,199 kB]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-pictures all 2021.20220204-1 [8,720 kB]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-latex-extra all 2021.20220204-1 [13.9 MB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-plain-generic all 2021.20220204-1 [27.5 MB]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tipa all 2:1.3-21 [2,967 kB]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy/universe amd64 texlive-xetex all 2021.20220204-1 [12.4 MB]\n",
            "Fetched 202 MB in 12s (17.1 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package fonts-droid-fallback.\n",
            "(Reading database ... 123614 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1build1_all.deb ...\n",
            "Unpacking fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Selecting previously unselected package fonts-lato.\n",
            "Preparing to unpack .../01-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package poppler-data.\n",
            "Preparing to unpack .../02-poppler-data_0.4.11-1_all.deb ...\n",
            "Unpacking poppler-data (0.4.11-1) ...\n",
            "Selecting previously unselected package tex-common.\n",
            "Preparing to unpack .../03-tex-common_6.17_all.deb ...\n",
            "Unpacking tex-common (6.17) ...\n",
            "Selecting previously unselected package fonts-urw-base35.\n",
            "Preparing to unpack .../04-fonts-urw-base35_20200910-1_all.deb ...\n",
            "Unpacking fonts-urw-base35 (20200910-1) ...\n",
            "Selecting previously unselected package libgs9-common.\n",
            "Preparing to unpack .../05-libgs9-common_9.55.0~dfsg1-0ubuntu5.9_all.deb ...\n",
            "Unpacking libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package libidn12:amd64.\n",
            "Preparing to unpack .../06-libidn12_1.38-4ubuntu1_amd64.deb ...\n",
            "Unpacking libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Selecting previously unselected package libijs-0.35:amd64.\n",
            "Preparing to unpack .../07-libijs-0.35_0.35-15build2_amd64.deb ...\n",
            "Unpacking libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Selecting previously unselected package libjbig2dec0:amd64.\n",
            "Preparing to unpack .../08-libjbig2dec0_0.19-3build2_amd64.deb ...\n",
            "Unpacking libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Selecting previously unselected package libgs9:amd64.\n",
            "Preparing to unpack .../09-libgs9_9.55.0~dfsg1-0ubuntu5.9_amd64.deb ...\n",
            "Unpacking libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Selecting previously unselected package libkpathsea6:amd64.\n",
            "Preparing to unpack .../10-libkpathsea6_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libwoff1:amd64.\n",
            "Preparing to unpack .../11-libwoff1_1.0.2-1build4_amd64.deb ...\n",
            "Unpacking libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Selecting previously unselected package dvisvgm.\n",
            "Preparing to unpack .../12-dvisvgm_2.13.1-1_amd64.deb ...\n",
            "Unpacking dvisvgm (2.13.1-1) ...\n",
            "Selecting previously unselected package fonts-lmodern.\n",
            "Preparing to unpack .../13-fonts-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking fonts-lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package fonts-noto-mono.\n",
            "Preparing to unpack .../14-fonts-noto-mono_20201225-1build1_all.deb ...\n",
            "Unpacking fonts-noto-mono (20201225-1build1) ...\n",
            "Selecting previously unselected package fonts-texgyre.\n",
            "Preparing to unpack .../15-fonts-texgyre_20180621-3.1_all.deb ...\n",
            "Unpacking fonts-texgyre (20180621-3.1) ...\n",
            "Selecting previously unselected package libapache-pom-java.\n",
            "Preparing to unpack .../16-libapache-pom-java_18-1_all.deb ...\n",
            "Unpacking libapache-pom-java (18-1) ...\n",
            "Selecting previously unselected package libcmark-gfm0.29.0.gfm.3:amd64.\n",
            "Preparing to unpack .../17-libcmark-gfm0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package libcmark-gfm-extensions0.29.0.gfm.3:amd64.\n",
            "Preparing to unpack .../18-libcmark-gfm-extensions0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package libcommons-parent-java.\n",
            "Preparing to unpack .../19-libcommons-parent-java_43-1_all.deb ...\n",
            "Unpacking libcommons-parent-java (43-1) ...\n",
            "Selecting previously unselected package libcommons-logging-java.\n",
            "Preparing to unpack .../20-libcommons-logging-java_1.2-2_all.deb ...\n",
            "Unpacking libcommons-logging-java (1.2-2) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../21-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libptexenc1:amd64.\n",
            "Preparing to unpack .../22-libptexenc1_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../23-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../24-ruby3.0_3.0.2-7ubuntu2.7_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.7) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../25-ruby-rubygems_3.3.5-2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../26-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../27-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../28-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../29-ruby-webrick_1.7.0-3_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../30-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../31-libruby3.0_3.0.2-7ubuntu2.7_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.7) ...\n",
            "Selecting previously unselected package libsynctex2:amd64.\n",
            "Preparing to unpack .../32-libsynctex2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libteckit0:amd64.\n",
            "Preparing to unpack .../33-libteckit0_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package libtexlua53:amd64.\n",
            "Preparing to unpack .../34-libtexlua53_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libtexluajit2:amd64.\n",
            "Preparing to unpack .../35-libtexluajit2_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package libzzip-0-13:amd64.\n",
            "Preparing to unpack .../36-libzzip-0-13_0.13.72+dfsg.1-1.1_amd64.deb ...\n",
            "Unpacking libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../37-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../38-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package lmodern.\n",
            "Preparing to unpack .../39-lmodern_2.004.5-6.1_all.deb ...\n",
            "Unpacking lmodern (2.004.5-6.1) ...\n",
            "Selecting previously unselected package pandoc-data.\n",
            "Preparing to unpack .../40-pandoc-data_2.9.2.1-3ubuntu2_all.deb ...\n",
            "Unpacking pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Selecting previously unselected package pandoc.\n",
            "Preparing to unpack .../41-pandoc_2.9.2.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Selecting previously unselected package preview-latex-style.\n",
            "Preparing to unpack .../42-preview-latex-style_12.2-1ubuntu1_all.deb ...\n",
            "Unpacking preview-latex-style (12.2-1ubuntu1) ...\n",
            "Selecting previously unselected package t1utils.\n",
            "Preparing to unpack .../43-t1utils_1.41-4build2_amd64.deb ...\n",
            "Unpacking t1utils (1.41-4build2) ...\n",
            "Selecting previously unselected package teckit.\n",
            "Preparing to unpack .../44-teckit_2.5.11+ds1-1_amd64.deb ...\n",
            "Unpacking teckit (2.5.11+ds1-1) ...\n",
            "Selecting previously unselected package tex-gyre.\n",
            "Preparing to unpack .../45-tex-gyre_20180621-3.1_all.deb ...\n",
            "Unpacking tex-gyre (20180621-3.1) ...\n",
            "Selecting previously unselected package texlive-binaries.\n",
            "Preparing to unpack .../46-texlive-binaries_2021.20210626.59705-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Selecting previously unselected package texlive-base.\n",
            "Preparing to unpack .../47-texlive-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-fonts-recommended.\n",
            "Preparing to unpack .../48-texlive-fonts-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-base.\n",
            "Preparing to unpack .../49-texlive-latex-base_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-base (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-recommended.\n",
            "Preparing to unpack .../50-texlive-latex-recommended_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-recommended (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive.\n",
            "Preparing to unpack .../51-texlive_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive (2021.20220204-1) ...\n",
            "Selecting previously unselected package libfontbox-java.\n",
            "Preparing to unpack .../52-libfontbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libfontbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package libpdfbox-java.\n",
            "Preparing to unpack .../53-libpdfbox-java_1%3a1.8.16-2_all.deb ...\n",
            "Unpacking libpdfbox-java (1:1.8.16-2) ...\n",
            "Selecting previously unselected package texlive-pictures.\n",
            "Preparing to unpack .../54-texlive-pictures_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-pictures (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-latex-extra.\n",
            "Preparing to unpack .../55-texlive-latex-extra_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-latex-extra (2021.20220204-1) ...\n",
            "Selecting previously unselected package texlive-plain-generic.\n",
            "Preparing to unpack .../56-texlive-plain-generic_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-plain-generic (2021.20220204-1) ...\n",
            "Selecting previously unselected package tipa.\n",
            "Preparing to unpack .../57-tipa_2%3a1.3-21_all.deb ...\n",
            "Unpacking tipa (2:1.3-21) ...\n",
            "Selecting previously unselected package texlive-xetex.\n",
            "Preparing to unpack .../58-texlive-xetex_2021.20220204-1_all.deb ...\n",
            "Unpacking texlive-xetex (2021.20220204-1) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up fonts-noto-mono (20201225-1build1) ...\n",
            "Setting up libwoff1:amd64 (1.0.2-1build4) ...\n",
            "Setting up libtexlua53:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libijs-0.35:amd64 (0.35-15build2) ...\n",
            "Setting up libtexluajit2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libfontbox-java (1:1.8.16-2) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up libzzip-0-13:amd64 (0.13.72+dfsg.1-1.1) ...\n",
            "Setting up fonts-urw-base35 (20200910-1) ...\n",
            "Setting up poppler-data (0.4.11-1) ...\n",
            "Setting up tex-common (6.17) ...\n",
            "update-language: texlive-base not installed and configured, doing nothing!\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libjbig2dec0:amd64 (0.19-3build2) ...\n",
            "Setting up libteckit0:amd64 (2.5.11+ds1-1) ...\n",
            "Setting up libapache-pom-java (18-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up t1utils (1.41-4build2) ...\n",
            "Setting up libidn12:amd64 (1.38-4ubuntu1) ...\n",
            "Setting up fonts-texgyre (20180621-3.1) ...\n",
            "Setting up libkpathsea6:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up ruby-webrick (1.7.0-3) ...\n",
            "Setting up libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up fonts-lmodern (2.004.5-6.1) ...\n",
            "Setting up libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up fonts-droid-fallback (1:6.0.1r16-1.1build1) ...\n",
            "Setting up pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up libsynctex2:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up libgs9-common (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up teckit (2.5.11+ds1-1) ...\n",
            "Setting up libpdfbox-java (1:1.8.16-2) ...\n",
            "Setting up libgs9:amd64 (9.55.0~dfsg1-0ubuntu5.9) ...\n",
            "Setting up preview-latex-style (12.2-1ubuntu1) ...\n",
            "Setting up libcommons-parent-java (43-1) ...\n",
            "Setting up dvisvgm (2.13.1-1) ...\n",
            "Setting up libcommons-logging-java (1.2-2) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up libptexenc1:amd64 (2021.20210626.59705-1ubuntu0.2) ...\n",
            "Setting up pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Setting up texlive-binaries (2021.20210626.59705-1ubuntu0.2) ...\n",
            "update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n",
            "update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n",
            "Setting up lmodern (2.004.5-6.1) ...\n",
            "Setting up texlive-base (2021.20220204-1) ...\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "/usr/bin/ucfr\n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n",
            "mktexlsr: Updating /var/lib/texmf/ls-R... \n",
            "mktexlsr: Done.\n",
            "tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n",
            "tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n",
            "tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n",
            "tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/tex-ini-files/pdftexconfig.tex\n",
            "Setting up tex-gyre (20180621-3.1) ...\n",
            "Setting up texlive-plain-generic (2021.20220204-1) ...\n",
            "Setting up texlive-latex-base (2021.20220204-1) ...\n",
            "Setting up texlive-latex-recommended (2021.20220204-1) ...\n",
            "Setting up texlive-pictures (2021.20220204-1) ...\n",
            "Setting up texlive-fonts-recommended (2021.20220204-1) ...\n",
            "Setting up tipa (2:1.3-21) ...\n",
            "Setting up texlive (2021.20220204-1) ...\n",
            "Setting up texlive-latex-extra (2021.20220204-1) ...\n",
            "Setting up texlive-xetex (2021.20220204-1) ...\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.7) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.7) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up ruby-rubygems (3.3.5-2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for tex-common (6.17) ...\n",
            "Running updmap-sys. This may take some time... done.\n",
            "Running mktexlsr /var/lib/texmf ... done.\n",
            "Building format(s) --all.\n",
            "\tThis may take some time... done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypandoc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LF-aF_caD0y",
        "outputId": "20fecfeb-3c13-4990-d384-a4d8b15b54a0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypandoc\n",
            "  Downloading pypandoc-1.13-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading pypandoc-1.13-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: pypandoc\n",
            "Successfully installed pypandoc-1.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liPX4isZb4YO",
        "outputId": "bbce935b-4a64-4e17-beb2-73e12e798260"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to PDF \"drive/My Drive/Colab Notebooks/NLP_Assign2.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV7e7NX9aIKn",
        "outputId": "b4a1f1c8-7467-4e57-daf7-7913118ecd05"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook drive/My Drive/Colab Notebooks/NLP_Assign2.ipynb to PDF\n",
            "[NbConvertApp] ERROR | Notebook JSON is invalid: Additional properties are not allowed ('metadata' was unexpected)\n",
            "\n",
            "Failed validating 'additionalProperties' in stream:\n",
            "\n",
            "On instance['cells'][45]['outputs'][0]:\n",
            "{'metadata': {'tags': None},\n",
            " 'name': 'stdout',\n",
            " 'output_type': 'stream',\n",
            " 'text': 'Training on chunk 1/96\\nEpoch 1/5\\n'}\n",
            "[NbConvertApp] Support files will be in NLP_Assign2_files/\n",
            "[NbConvertApp] Making directory ./NLP_Assign2_files\n",
            "[NbConvertApp] Making directory ./NLP_Assign2_files\n",
            "[NbConvertApp] Writing 296682 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 216847 bytes to drive/My Drive/Colab Notebooks/NLP_Assign2.pdf\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUOZb+/3KvqTVz98DLYtn6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}